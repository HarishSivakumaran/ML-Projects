{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing all the libraries necessary for the project\nimport jax\nimport flax\nimport numpy as np\nimport jax.numpy as jnp\nimport tensorflow as tf\nfrom jax import random\nimport pandas as pd\nimport os\nfrom flax import linen as nn # the Linen API\nfrom flax.training import train_state \nimport optax\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:00:04.803297Z","iopub.execute_input":"2025-06-09T09:00:04.803610Z","iopub.status.idle":"2025-06-09T09:00:26.276429Z","shell.execute_reply.started":"2025-06-09T09:00:04.803589Z","shell.execute_reply":"2025-06-09T09:00:26.275550Z"}},"outputs":[{"name":"stderr","text":"2025-06-09 09:00:10.687374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749459610.977280      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749459611.057126      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# List all the available devices\njax.local_devices()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:00:26.278101Z","iopub.execute_input":"2025-06-09T09:00:26.278760Z","iopub.status.idle":"2025-06-09T09:00:26.843833Z","shell.execute_reply.started":"2025-06-09T09:00:26.278732Z","shell.execute_reply":"2025-06-09T09:00:26.842893Z"}},"outputs":[{"name":"stderr","text":"INFO:2025-06-09 09:00:26,817:jax._src.xla_bridge:924: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\nINFO:2025-06-09 09:00:26,836:jax._src.xla_bridge:924: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[CpuDevice(id=0)]"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"mnist_train = pd.read_csv('../input/digit-recognizer/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:00:26.844804Z","iopub.execute_input":"2025-06-09T09:00:26.845191Z","iopub.status.idle":"2025-06-09T09:00:30.295710Z","shell.execute_reply.started":"2025-06-09T09:00:26.845160Z","shell.execute_reply":"2025-06-09T09:00:30.294862Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"mnist_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:00:30.297590Z","iopub.execute_input":"2025-06-09T09:00:30.297906Z","iopub.status.idle":"2025-06-09T09:00:30.335940Z","shell.execute_reply.started":"2025-06-09T09:00:30.297855Z","shell.execute_reply":"2025-06-09T09:00:30.334934Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0          1       0       0       0       0       0       0       0       0   \n1          0       0       0       0       0       0       0       0       0   \n2          1       0       0       0       0       0       0       0       0   \n3          4       0       0       0       0       0       0       0       0   \n4          0       0       0       0       0       0       0       0       0   \n...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n41995      0       0       0       0       0       0       0       0       0   \n41996      1       0       0       0       0       0       0       0       0   \n41997      7       0       0       0       0       0       0       0       0   \n41998      6       0       0       0       0       0       0       0       0   \n41999      9       0       0       0       0       0       0       0       0   \n\n       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n0           0  ...         0         0         0         0         0   \n1           0  ...         0         0         0         0         0   \n2           0  ...         0         0         0         0         0   \n3           0  ...         0         0         0         0         0   \n4           0  ...         0         0         0         0         0   \n...       ...  ...       ...       ...       ...       ...       ...   \n41995       0  ...         0         0         0         0         0   \n41996       0  ...         0         0         0         0         0   \n41997       0  ...         0         0         0         0         0   \n41998       0  ...         0         0         0         0         0   \n41999       0  ...         0         0         0         0         0   \n\n       pixel779  pixel780  pixel781  pixel782  pixel783  \n0             0         0         0         0         0  \n1             0         0         0         0         0  \n2             0         0         0         0         0  \n3             0         0         0         0         0  \n4             0         0         0         0         0  \n...         ...       ...       ...       ...       ...  \n41995         0         0         0         0         0  \n41996         0         0         0         0         0  \n41997         0         0         0         0         0  \n41998         0         0         0         0         0  \n41999         0         0         0         0         0  \n\n[42000 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41996</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41997</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41998</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41999</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>42000 rows × 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"class FfwModel():\n    def __init__(self, n_x, n_y, key):\n        self.n_x = n_x\n        self.n_y = n_y\n        k1, k2 = random.split(key)\n        self.W1 = random.uniform(k1, (n_x, 100)) * 0.01\n        self.W2 = random.uniform(k2, (100, n_y)) * 0.01\n\n    def forward(self, X_batch, y_batch=None):\n        Z1 = jnp.dot(self.W1.T, X_batch)\n        A1 = jax.nn.relu(Z1)\n        Z2 = jnp.dot(self.W2.T, A1)\n        A2 = 1 / (1 + jnp.exp(-Z2))\n\n        if(y_batch is not None):\n            # cross entropy\n            one_hot_labels = jax.nn.one_hot(y_batch, num_classes=10).T.reshape(10,y_batch.shape[1])\n            nll = -(one_hot_labels * jnp.log(A2) + (1-one_hot_labels) * jnp.log(1-A2))\n            cost = jnp.mean(jnp.sum(nll, axis=-1))\n            # print(nll[:, :3])\n            # print(A2[:, :3])\n            # print(y_batch[:, :3])\n            # print(jnp.argmax(A2, axis=0) == y_batch)\n            accuracy = jnp.mean(jnp.argmax(A2, axis=0) == y_batch)\n            self.Z1 = Z1\n            return A2, A1, cost, accuracy\n\n        return A2, A1, None, None\n\n\n    def backward(self, A2, A1, A0, y_batch, learning_rate=0.003):\n        dL2 = (1/y_batch.shape[1])\n        one_hot_labels = jax.nn.one_hot(y_batch, num_classes=10).T.reshape(10,y_batch.shape[1])\n        # dA2 = ((A2-one_hot_labels)/(A2*(1-A2))) * dL2\n        # dZ2 = dA2 * (A2*(1-A2)) \n        dZ2 = dL2 * (A2-one_hot_labels)\n        dW2 = jnp.dot(A1, dZ2.T) \n        dA1 = jnp.dot(self.W2, dZ2)\n        dZ1 = self.relu_derivative(self.Z1) * dA1\n        dW1 = jnp.dot(A0, dZ1.T) \n        self.W1 -= (learning_rate*dW1)\n        self.W2 -= (learning_rate*dW2)\n        \n\n    def relu_derivative(self, x):\n        return np.where(x >= 0, 1, 0)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:00:30.336733Z","iopub.execute_input":"2025-06-09T09:00:30.337057Z","iopub.status.idle":"2025-06-09T09:00:30.348998Z","shell.execute_reply.started":"2025-06-09T09:00:30.337036Z","shell.execute_reply":"2025-06-09T09:00:30.347854Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"labels = mnist_train[\"label\"]\nfeatures = mnist_train.drop(labels = [\"label\"],axis = 1)\nfeatures = features/255.0\nlabels = labels.to_numpy().reshape(1, -1)\nfeatures = features.values.T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:00:30.350132Z","iopub.execute_input":"2025-06-09T09:00:30.350477Z","iopub.status.idle":"2025-06-09T09:00:30.565602Z","shell.execute_reply.started":"2025-06-09T09:00:30.350454Z","shell.execute_reply":"2025-06-09T09:00:30.564299Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(features.shape)\nprint(labels.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:00:30.567642Z","iopub.execute_input":"2025-06-09T09:00:30.568062Z","iopub.status.idle":"2025-06-09T09:00:30.573247Z","shell.execute_reply.started":"2025-06-09T09:00:30.568034Z","shell.execute_reply":"2025-06-09T09:00:30.571942Z"}},"outputs":[{"name":"stdout","text":"(784, 42000)\n(1, 42000)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"epochs = 200\nbatch_size = 100\nrng = jax.random.PRNGKey(7)\nrng, init_rng = jax.random.split(rng)\nmodel = FfwModel(features.shape[0], 10, rng)\n\nfor epoch in range(epochs):\n    cost = None\n    accuracy = None\n    for step in range(features.shape[1]//batch_size):\n        start = step*batch_size\n        end = ((step+1)*batch_size)\n        X_batch = features[:, start:end]\n        y_batch = labels[:, start:end]\n        A2, A1, cost, accuracy = model.forward(X_batch, y_batch)\n        model.backward(A2, A1, X_batch, y_batch, 0.003)\n    print(f'epoch: {epoch} cost: {cost} train_acc:{accuracy*100}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:00:30.574399Z","iopub.execute_input":"2025-06-09T09:00:30.574860Z"}},"outputs":[{"name":"stdout","text":"epoch: 0 cost: 34.44282913208008 train_acc:4.999999523162842\nepoch: 1 cost: 34.15329360961914 train_acc:4.999999523162842\nepoch: 2 cost: 33.80289840698242 train_acc:14.999999046325684\nepoch: 3 cost: 33.03246307373047 train_acc:16.0\nepoch: 4 cost: 31.11858558654785 train_acc:55.0\nepoch: 5 cost: 27.856369018554688 train_acc:63.0\nepoch: 6 cost: 24.50994300842285 train_acc:66.99999237060547\nepoch: 7 cost: 21.900693893432617 train_acc:69.0\nepoch: 8 cost: 19.928089141845703 train_acc:74.0\nepoch: 9 cost: 18.34296989440918 train_acc:77.0\nepoch: 10 cost: 16.97061538696289 train_acc:78.0\nepoch: 11 cost: 15.753348350524902 train_acc:78.0\nepoch: 12 cost: 14.67704963684082 train_acc:79.99999237060547\nepoch: 13 cost: 13.741900444030762 train_acc:82.0\nepoch: 14 cost: 12.940051078796387 train_acc:83.0\nepoch: 15 cost: 12.26222038269043 train_acc:85.99999237060547\nepoch: 16 cost: 11.685172080993652 train_acc:85.0\nepoch: 17 cost: 11.18864917755127 train_acc:85.0\nepoch: 18 cost: 10.751402854919434 train_acc:85.0\nepoch: 19 cost: 10.360127449035645 train_acc:85.99999237060547\nepoch: 20 cost: 10.002116203308105 train_acc:89.0\nepoch: 21 cost: 9.673014640808105 train_acc:90.0\nepoch: 22 cost: 9.36390209197998 train_acc:90.0\nepoch: 23 cost: 9.070113182067871 train_acc:91.0\nepoch: 24 cost: 8.793620109558105 train_acc:91.0\nepoch: 25 cost: 8.534029006958008 train_acc:91.0\nepoch: 26 cost: 8.288674354553223 train_acc:91.0\nepoch: 27 cost: 8.05698013305664 train_acc:91.99999237060547\nepoch: 28 cost: 7.841137886047363 train_acc:93.0\nepoch: 29 cost: 7.642055511474609 train_acc:93.0\nepoch: 30 cost: 7.457222938537598 train_acc:93.0\nepoch: 31 cost: 7.284738063812256 train_acc:93.0\nepoch: 32 cost: 7.122947692871094 train_acc:93.0\nepoch: 33 cost: 6.972116947174072 train_acc:93.0\nepoch: 34 cost: 6.830441951751709 train_acc:91.99999237060547\nepoch: 35 cost: 6.6963677406311035 train_acc:91.99999237060547\nepoch: 36 cost: 6.570135593414307 train_acc:91.99999237060547\nepoch: 37 cost: 6.453395843505859 train_acc:91.99999237060547\nepoch: 38 cost: 6.343796730041504 train_acc:91.99999237060547\nepoch: 39 cost: 6.239862442016602 train_acc:91.99999237060547\nepoch: 40 cost: 6.142127990722656 train_acc:91.99999237060547\nepoch: 41 cost: 6.0500640869140625 train_acc:91.99999237060547\nepoch: 42 cost: 5.961819171905518 train_acc:91.99999237060547\nepoch: 43 cost: 5.877499103546143 train_acc:91.99999237060547\nepoch: 44 cost: 5.796000957489014 train_acc:91.99999237060547\nepoch: 45 cost: 5.717520236968994 train_acc:91.99999237060547\nepoch: 46 cost: 5.642807960510254 train_acc:93.0\nepoch: 47 cost: 5.570120811462402 train_acc:93.0\nepoch: 48 cost: 5.500363826751709 train_acc:93.0\nepoch: 49 cost: 5.432939529418945 train_acc:93.0\nepoch: 50 cost: 5.36787748336792 train_acc:93.0\nepoch: 51 cost: 5.305756568908691 train_acc:93.0\nepoch: 52 cost: 5.244176387786865 train_acc:93.0\nepoch: 53 cost: 5.185615539550781 train_acc:93.0\nepoch: 54 cost: 5.12936544418335 train_acc:93.0\nepoch: 55 cost: 5.074734687805176 train_acc:93.0\nepoch: 56 cost: 5.021015167236328 train_acc:93.0\nepoch: 57 cost: 4.969230651855469 train_acc:93.0\nepoch: 58 cost: 4.919968128204346 train_acc:93.0\nepoch: 59 cost: 4.871978759765625 train_acc:93.0\nepoch: 60 cost: 4.824774265289307 train_acc:93.0\nepoch: 61 cost: 4.778342247009277 train_acc:93.0\nepoch: 62 cost: 4.733445167541504 train_acc:93.0\nepoch: 63 cost: 4.6883368492126465 train_acc:93.0\nepoch: 64 cost: 4.643935680389404 train_acc:93.0\nepoch: 65 cost: 4.600694179534912 train_acc:93.0\nepoch: 66 cost: 4.558307647705078 train_acc:93.0\nepoch: 67 cost: 4.517167091369629 train_acc:93.0\nepoch: 68 cost: 4.4775824546813965 train_acc:93.0\nepoch: 69 cost: 4.43884801864624 train_acc:93.0\nepoch: 70 cost: 4.400439262390137 train_acc:93.0\nepoch: 71 cost: 4.361795902252197 train_acc:93.0\nepoch: 72 cost: 4.322759628295898 train_acc:93.0\nepoch: 73 cost: 4.2850847244262695 train_acc:94.0\nepoch: 74 cost: 4.24818229675293 train_acc:94.0\nepoch: 75 cost: 4.211787223815918 train_acc:94.0\nepoch: 76 cost: 4.175417423248291 train_acc:94.0\nepoch: 77 cost: 4.140155792236328 train_acc:94.0\nepoch: 78 cost: 4.104674816131592 train_acc:94.0\nepoch: 79 cost: 4.069572448730469 train_acc:94.0\nepoch: 80 cost: 4.035037517547607 train_acc:94.0\nepoch: 81 cost: 4.001208782196045 train_acc:94.0\nepoch: 82 cost: 3.967884063720703 train_acc:94.0\nepoch: 83 cost: 3.9352519512176514 train_acc:94.0\nepoch: 84 cost: 3.902514696121216 train_acc:94.0\nepoch: 85 cost: 3.871225118637085 train_acc:94.0\nepoch: 86 cost: 3.8403217792510986 train_acc:94.0\nepoch: 87 cost: 3.8095428943634033 train_acc:94.0\nepoch: 88 cost: 3.7788517475128174 train_acc:94.0\nepoch: 89 cost: 3.748997449874878 train_acc:94.0\nepoch: 90 cost: 3.719831943511963 train_acc:94.0\nepoch: 91 cost: 3.690876007080078 train_acc:94.0\nepoch: 92 cost: 3.6627442836761475 train_acc:94.0\nepoch: 93 cost: 3.6346042156219482 train_acc:94.0\nepoch: 94 cost: 3.6069953441619873 train_acc:94.0\nepoch: 95 cost: 3.580413818359375 train_acc:94.0\nepoch: 96 cost: 3.5531041622161865 train_acc:94.0\nepoch: 97 cost: 3.525125503540039 train_acc:94.0\nepoch: 98 cost: 3.4972026348114014 train_acc:94.0\nepoch: 99 cost: 3.4696357250213623 train_acc:94.0\nepoch: 100 cost: 3.442307233810425 train_acc:94.0\nepoch: 101 cost: 3.4150331020355225 train_acc:94.0\nepoch: 102 cost: 3.387629270553589 train_acc:94.0\nepoch: 103 cost: 3.3605287075042725 train_acc:94.0\nepoch: 104 cost: 3.3337745666503906 train_acc:94.0\nepoch: 105 cost: 3.307497024536133 train_acc:94.0\nepoch: 106 cost: 3.2816624641418457 train_acc:94.0\nepoch: 107 cost: 3.256012439727783 train_acc:94.0\nepoch: 108 cost: 3.2308406829833984 train_acc:94.0\nepoch: 109 cost: 3.206289291381836 train_acc:94.0\nepoch: 110 cost: 3.1817474365234375 train_acc:94.0\nepoch: 111 cost: 3.1571714878082275 train_acc:94.0\nepoch: 112 cost: 3.133113384246826 train_acc:94.0\nepoch: 113 cost: 3.1091926097869873 train_acc:94.0\nepoch: 114 cost: 3.0856361389160156 train_acc:94.0\nepoch: 115 cost: 3.0621988773345947 train_acc:94.0\nepoch: 116 cost: 3.0383896827697754 train_acc:94.0\nepoch: 117 cost: 3.0150234699249268 train_acc:94.0\nepoch: 118 cost: 2.9919371604919434 train_acc:94.0\nepoch: 119 cost: 2.968961477279663 train_acc:94.0\nepoch: 120 cost: 2.946453809738159 train_acc:94.0\nepoch: 121 cost: 2.9249227046966553 train_acc:94.0\nepoch: 122 cost: 2.9025721549987793 train_acc:95.0\nepoch: 123 cost: 2.880483865737915 train_acc:95.0\nepoch: 124 cost: 2.8585221767425537 train_acc:95.0\nepoch: 125 cost: 2.8367695808410645 train_acc:95.0\nepoch: 126 cost: 2.815331220626831 train_acc:95.0\nepoch: 127 cost: 2.7942874431610107 train_acc:96.0\nepoch: 128 cost: 2.7729525566101074 train_acc:96.0\nepoch: 129 cost: 2.75229811668396 train_acc:96.0\nepoch: 130 cost: 2.7316086292266846 train_acc:96.0\nepoch: 131 cost: 2.7111496925354004 train_acc:96.0\nepoch: 132 cost: 2.6912801265716553 train_acc:96.0\nepoch: 133 cost: 2.671398878097534 train_acc:96.0\nepoch: 134 cost: 2.6518428325653076 train_acc:96.0\nepoch: 135 cost: 2.63211989402771 train_acc:96.0\nepoch: 136 cost: 2.6126651763916016 train_acc:96.0\nepoch: 137 cost: 2.5936172008514404 train_acc:96.0\nepoch: 138 cost: 2.5749661922454834 train_acc:96.0\nepoch: 139 cost: 2.5564417839050293 train_acc:96.0\nepoch: 140 cost: 2.538090467453003 train_acc:96.0\nepoch: 141 cost: 2.519859790802002 train_acc:97.0\nepoch: 142 cost: 2.501920700073242 train_acc:97.0\nepoch: 143 cost: 2.484306812286377 train_acc:97.0\nepoch: 144 cost: 2.466930866241455 train_acc:97.0\nepoch: 145 cost: 2.4495017528533936 train_acc:97.0\nepoch: 146 cost: 2.4323647022247314 train_acc:97.0\nepoch: 147 cost: 2.415738105773926 train_acc:97.0\nepoch: 148 cost: 2.3988144397735596 train_acc:97.0\nepoch: 149 cost: 2.382326126098633 train_acc:97.0\nepoch: 150 cost: 2.3652751445770264 train_acc:97.0\nepoch: 151 cost: 2.3487532138824463 train_acc:97.0\nepoch: 152 cost: 2.3327713012695312 train_acc:97.0\nepoch: 153 cost: 2.316890239715576 train_acc:97.0\nepoch: 154 cost: 2.301236629486084 train_acc:97.0\nepoch: 155 cost: 2.285797119140625 train_acc:97.0\nepoch: 156 cost: 2.2710864543914795 train_acc:97.0\nepoch: 157 cost: 2.256716251373291 train_acc:97.0\nepoch: 158 cost: 2.2423083782196045 train_acc:97.0\nepoch: 159 cost: 2.228074789047241 train_acc:97.0\nepoch: 160 cost: 2.213855266571045 train_acc:97.0\nepoch: 161 cost: 2.1999576091766357 train_acc:97.0\nepoch: 162 cost: 2.186375379562378 train_acc:97.0\nepoch: 163 cost: 2.1727442741394043 train_acc:97.99999237060547\nepoch: 164 cost: 2.1592469215393066 train_acc:97.99999237060547\nepoch: 165 cost: 2.145738363265991 train_acc:97.99999237060547\nepoch: 166 cost: 2.1329963207244873 train_acc:97.99999237060547\nepoch: 167 cost: 2.1199653148651123 train_acc:97.99999237060547\nepoch: 168 cost: 2.106955051422119 train_acc:97.99999237060547\nepoch: 169 cost: 2.0941543579101562 train_acc:97.99999237060547\nepoch: 170 cost: 2.0814709663391113 train_acc:97.99999237060547\nepoch: 171 cost: 2.0687954425811768 train_acc:97.99999237060547\nepoch: 172 cost: 2.056131362915039 train_acc:97.99999237060547\nepoch: 173 cost: 2.0438058376312256 train_acc:97.99999237060547\nepoch: 174 cost: 2.031909704208374 train_acc:97.99999237060547\nepoch: 175 cost: 2.020094633102417 train_acc:97.99999237060547\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"A2, _, _, _ = model.forward(features[:, 700])\nprint(A2)\nprint(jnp.argmax(A2, axis=0))\nprint(labels[0,700])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:07:52.547495Z","iopub.execute_input":"2025-06-09T09:07:52.547911Z","iopub.status.idle":"2025-06-09T09:07:52.810174Z","shell.execute_reply.started":"2025-06-09T09:07:52.547855Z","shell.execute_reply":"2025-06-09T09:07:52.808901Z"}},"outputs":[{"name":"stdout","text":"[1.8518037e-04 5.8256609e-07 8.2342438e-03 3.9470393e-05 9.9384272e-01\n 1.8130058e-02 7.1979505e-03 3.2741819e-03 1.7154013e-04 4.0781719e-04]\n4\n4\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"test = pd.read_csv('../input/digit-recognizer/test.csv')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:07:57.249699Z","iopub.execute_input":"2025-06-09T09:07:57.250062Z","iopub.status.idle":"2025-06-09T09:07:59.185487Z","shell.execute_reply.started":"2025-06-09T09:07:57.250036Z","shell.execute_reply":"2025-06-09T09:07:59.184703Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"test = test\nfeatures = test.to_numpy().T\npredictions, _, _, _ = model.forward(features)\nprint(predictions.shape)\nlabels = jnp.argmax(predictions, axis=0)\nprint(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:12:35.903451Z","iopub.execute_input":"2025-06-09T09:12:35.903739Z","iopub.status.idle":"2025-06-09T09:12:36.161019Z","shell.execute_reply.started":"2025-06-09T09:12:35.903719Z","shell.execute_reply":"2025-06-09T09:12:36.160167Z"}},"outputs":[{"name":"stdout","text":"(10, 28000)\n[2 0 9 ... 3 9 2]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"submission = pd.DataFrame( {\"ImageId\":test.index+1 , \"Label\": labels} ) #! creat a Taple for Ruslt \nsubmission.to_csv('/kaggle/working/submission.csv' , index= False)\nsubmission.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:16:55.267819Z","iopub.execute_input":"2025-06-09T09:16:55.268196Z","iopub.status.idle":"2025-06-09T09:16:55.305893Z","shell.execute_reply.started":"2025-06-09T09:16:55.268172Z","shell.execute_reply":"2025-06-09T09:16:55.304637Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   ImageId  Label\n0        1      2\n1        2      0\n2        3      9\n3        4      9\n4        5      3\n5        6      7\n6        7      0\n7        8      3\n8        9      0\n9       10      3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}