{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch.utils.tensorboard import SummaryWriter\n\n# Math\nimport math\n\n# HuggingFace libraries \nfrom datasets import load_dataset\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import WordLevel\nfrom tokenizers.trainers import WordLevelTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\n\n# Pathlib \nfrom pathlib import Path\n\n# typing\nfrom typing import Any\n\n# Library for progress bars in loops\nfrom tqdm import tqdm\n\n# Importing library of warnings\nimport warnings","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.707353Z","iopub.execute_input":"2025-09-30T05:02:42.707615Z","iopub.status.idle":"2025-09-30T05:02:42.712261Z","shell.execute_reply.started":"2025-09-30T05:02:42.707595Z","shell.execute_reply":"2025-09-30T05:02:42.711463Z"}},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":"# Architecture","metadata":{}},{"cell_type":"markdown","source":"![Image](https://shreyansh26.github.io/assets/img/posts_images/attention/arch.PNG)","metadata":{}},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"markdown","source":"![Tokenizer](https://i.ytimg.com/vi/hL4ZnAWSyuU/sddefault.jpg)","metadata":{}},{"cell_type":"code","source":"def build_tokenizer(config, ds, lang):\n    \n    # Crating a file path for the tokenizer \n    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n    \n    # Checking if Tokenizer already exists\n    if not Path.exists(tokenizer_path): \n        \n        # If it doesn't exist, we create a new one\n        tokenizer = Tokenizer(WordLevel(unk_token = '[UNK]')) # Initializing a new world-level tokenizer\n        tokenizer.pre_tokenizer = Whitespace() # We will split the text into tokens based on whitespace\n        \n        # Creating a trainer for the new tokenizer\n        trainer = WordLevelTrainer(special_tokens = [\"[UNK]\", \"[PAD]\", \n                                                     \"[SOS]\", \"[EOS]\"], min_frequency = 2) # Defining Word Level strategy and special tokens\n        \n        # Training new tokenizer on sentences from the dataset and language specified \n        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer = trainer)\n        tokenizer.save(str(tokenizer_path)) # Saving trained tokenizer to the file path specified at the beginning of the function\n    else:\n        tokenizer = Tokenizer.from_file(str(tokenizer_path)) # If the tokenizer already exist, we load it\n    return tokenizer # Returns the loaded tokenizer or the trained tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.713214Z","iopub.execute_input":"2025-09-30T05:02:42.713457Z","iopub.status.idle":"2025-09-30T05:02:42.723622Z","shell.execute_reply.started":"2025-09-30T05:02:42.713442Z","shell.execute_reply":"2025-09-30T05:02:42.722897Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"def get_config():\n    return{\n        'batch_size': 8,\n        'num_epochs': 20,\n        'lr': 10**-4,\n        'seq_len': 350,\n        'd_model': 512, # Dimensions of the embeddings in the Transformer. 512 like in the \"Attention Is All You Need\" paper.\n        'lang_src': 'en',\n        'lang_tgt': 'it',\n        'model_folder': 'weights',\n        'model_basename': 'translation_model_',\n        'preload': None,\n        'tokenizer_file': 'tokenizer_{0}.json',\n        'experiment_name': 'runs/translation_model',\n        'encoder_layers': 6,\n        'decoder_layers': 6,\n        'p_drop': 0.1,\n        'dff': 2048,\n        'n_heads': 8\n    }\n\nconfig = get_config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.724664Z","iopub.execute_input":"2025-09-30T05:02:42.725345Z","iopub.status.idle":"2025-09-30T05:02:42.739230Z","shell.execute_reply.started":"2025-09-30T05:02:42.725317Z","shell.execute_reply":"2025-09-30T05:02:42.738657Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"def get_all_sentences(ds, lang):\n    for pair in ds:\n        yield pair['translation'][lang]\n        \ntokenizer_src = None\ntokenizer_tgt = None\ntrain_ds = None\ndef get_ds(config):\n    \n    # Loading the train portion of the OpusBooks dataset.\n    # The Language pairs will be defined in the 'config' dictionary we will build later\n    ds_raw = load_dataset('opus_books', f'{config[\"lang_src\"]}-{config[\"lang_tgt\"]}', split = 'train') \n    \n    # Building or loading tokenizer for both the source and target languages \n    tokenizer_src = build_tokenizer(config, ds_raw, config['lang_src'])\n    tokenizer_tgt = build_tokenizer(config, ds_raw, config['lang_tgt'])\n    \n    # Splitting the dataset for training and validation \n    train_ds_size = int(0.9 * len(ds_raw)) # 90% for training\n    val_ds_size = len(ds_raw) - train_ds_size # 10% for validation\n    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size]) # Randomly splitting the dataset\n                                    \n    # Processing data with the BilingualDataset class, which we will define below\n    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n                                    \n    # Iterating over the entire dataset and printing the maximum length found in the sentences of both the source and target languages\n    max_len_src = 0\n    max_len_tgt = 0\n    for pair in ds_raw:\n        src_ids = tokenizer_src.encode(pair['translation'][config['lang_src']]).ids\n        tgt_ids = tokenizer_src.encode(pair['translation'][config['lang_tgt']]).ids\n        max_len_src = max(max_len_src, len(src_ids))\n        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n        \n    print(f'Max length of source sentence: {max_len_src}')\n    print(f'Max length of target sentence: {max_len_tgt}')\n    \n    # Creating dataloaders for the training and validadion sets\n    # Dataloaders are used to iterate over the dataset in batches during training and validation\n    train_dataloader = DataLoader(train_ds, batch_size = config['batch_size'], shuffle = True) # Batch size will be defined in the config dictionary\n    val_dataloader = DataLoader(val_ds, batch_size = 1, shuffle = True)\n    \n    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt # Returning the DataLoader objects and tokenizers\n\ndef casual_mask(size):\n        # Creating a square matrix of dimensions 'size x size' filled with ones\n        mask = torch.triu(torch.ones(1, size, size), diagonal = 1).type(torch.int)\n        return mask == 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.740033Z","iopub.execute_input":"2025-09-30T05:02:42.740259Z","iopub.status.idle":"2025-09-30T05:02:42.750917Z","shell.execute_reply.started":"2025-09-30T05:02:42.740244Z","shell.execute_reply":"2025-09-30T05:02:42.750364Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"class BilingualDataset(Dataset):\n    \n    # This takes in the dataset contaning sentence pairs, the tokenizers for target and source languages, and the strings of source and target languages\n    # 'seq_len' defines the sequence length for both languages\n    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len) -> None:\n        super().__init__()\n        \n        self.seq_len = seq_len\n        self.ds = ds\n        self.tokenizer_src = tokenizer_src\n        self.tokenizer_tgt = tokenizer_tgt\n        self.src_lang = src_lang\n        self.tgt_lang = tgt_lang\n        \n        # Defining special tokens by using the target language tokenizer\n        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n\n        \n    # Total number of instances in the dataset (some pairs are larger than others)\n    def __len__(self):\n        return len(self.ds)\n    \n    # Using the index to retrive source and target texts\n    def __getitem__(self, index: Any) -> Any:\n        src_target_pair = self.ds[index]\n        src_text = src_target_pair['translation'][self.src_lang]\n        tgt_text = src_target_pair['translation'][self.tgt_lang]\n        \n        # Tokenizing source and target texts \n        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n        \n        # Computing how many padding tokens need to be added to the tokenized texts \n        # Source tokens\n        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2 # Subtracting the two '[EOS]' and '[SOS]' special tokens\n        # Target tokens\n        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1 # Subtracting the '[SOS]' special token\n        \n        # If the texts exceed the 'seq_len' allowed, it will raise an error. This means that one of the sentences in the pair is too long to be processed\n        # given the current sequence length limit (this will be defined in the config dictionary below)\n        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n            raise ValueError('Sentence is too long')\n         \n        # Building the encoder input tensor by combining several elements\n        encoder_input = torch.cat(\n            [\n            self.sos_token, # inserting the '[SOS]' token\n            torch.tensor(enc_input_tokens, dtype = torch.int64), # Inserting the tokenized source text\n            self.eos_token, # Inserting the '[EOS]' token\n            torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype = torch.int64) # Addind padding tokens\n            ]\n        )\n        \n        # Building the decoder input tensor by combining several elements\n        decoder_input = torch.cat(\n            [\n                self.sos_token, # inserting the '[SOS]' token \n                torch.tensor(dec_input_tokens, dtype = torch.int64), # Inserting the tokenized target text\n                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype = torch.int64) # Addind padding tokens\n            ]\n        \n        )\n        \n        # Creating a label tensor, the expected output for training the model\n        label = torch.cat(\n            [\n                torch.tensor(dec_input_tokens, dtype = torch.int64), # Inserting the tokenized target text\n                self.eos_token, # Inserting the '[EOS]' token \n                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype = torch.int64) # Adding padding tokens\n                \n            ]\n        )\n        \n        # Ensuring that the length of each tensor above is equal to the defined 'seq_len'\n        assert encoder_input.size(0) == self.seq_len\n        assert decoder_input.size(0) == self.seq_len\n        assert label.size(0) == self.seq_len\n        \n        return {\n            'encoder_input': encoder_input,\n            'decoder_input': decoder_input, \n            'encoder_mask': (encoder_input != self.pad_token).unsqueeze(0).int(),\n            'decoder_mask': (decoder_input != self.pad_token).unsqueeze(0).int() & (causal_mask(decoder_input.size(0)).squeeze(0)), \n            'label': label,\n            'src_text': src_text,\n            'tgt_text': tgt_text\n        }    \n\ndef causal_mask(size):\n        # Creating a square matrix of dimensions 'size x size' filled with ones\n        mask = torch.triu(torch.ones(1, size, size), diagonal = 1).type(torch.int)\n        return mask == 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.863929Z","iopub.execute_input":"2025-09-30T05:02:42.864357Z","iopub.status.idle":"2025-09-30T05:02:42.875045Z","shell.execute_reply.started":"2025-09-30T05:02:42.864341Z","shell.execute_reply":"2025-09-30T05:02:42.874333Z"}},"outputs":[],"execution_count":64},{"cell_type":"markdown","source":"# Token Embedding","metadata":{}},{"cell_type":"code","source":"class TokenEmbeddings(nn.Module):\n    def __init__(self, d_model, vocab_size):\n        super().__init__()\n        self.d_model = d_model\n        self.vocab_size = vocab_size\n        self.embeddings = nn.Embedding(vocab_size, d_model)\n\n    def forward(self, x):\n        return self.embeddings(x) * math.sqrt(self.d_model) # Normalizing the variance of the embedding\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.876387Z","iopub.execute_input":"2025-09-30T05:02:42.876623Z","iopub.status.idle":"2025-09-30T05:02:42.892028Z","shell.execute_reply.started":"2025-09-30T05:02:42.876601Z","shell.execute_reply":"2025-09-30T05:02:42.891512Z"}},"outputs":[],"execution_count":65},{"cell_type":"markdown","source":"# Positional Encoding\n\n<p style=\"\n    margin-bottom: 5; \n    font-size: 22px;\n    font-weight: 300;\n    font-family: 'Helvetica Neue', sans-serif;\n    color: #000000; \n  \">\n    \\begin{equation}\n    \\text{Even Indices } (2i): \\quad \\text{PE(pos, } 2i) = \\sin\\left(\\frac{\\text{pos}}{10000^{2i / d_{model}}}\\right)\n    \\end{equation}\n</p>\n\n<p style=\"\n    margin-bottom: 5; \n    font-size: 22px;\n    font-weight: 300;\n    font-family: 'Helvetica Neue', sans-serif;\n    color: #000000; \n  \">\n    \\begin{equation}\n    \\text{Odd Indices } (2i + 1): \\quad \\text{PE(pos, } 2i + 1) = \\cos\\left(\\frac{\\text{pos}}{10000^{2i / d_{model}}}\\right)\n    \\end{equation}\n</p>","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model: int, seq_len: int):\n        super().__init__()\n        self.d_model = d_model\n        self.seq_len = seq_len\n        encodings = torch.zeros(seq_len, d_model)\n        pos = torch.arange(0, seq_len, dtype = torch.float).unsqueeze(1) # [seq_len, 1]\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        encodings[:, 0::2] = torch.sin(pos * div_term)\n        encodings[:, 1::2] = torch.cos(pos * div_term)\n        encodings = encodings.unsqueeze(0) # add a batch dimension\n        self.register_buffer('encodings', encodings) # Buffer is a tensor not considered as a model parameter\n\n\n    def forward(self, x):\n        return x + (self.encodings[:, :x.shape[1], :]).requires_grad_(False)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.892759Z","iopub.execute_input":"2025-09-30T05:02:42.892930Z","iopub.status.idle":"2025-09-30T05:02:42.902500Z","shell.execute_reply.started":"2025-09-30T05:02:42.892916Z","shell.execute_reply":"2025-09-30T05:02:42.901749Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"posm = PositionalEncoding(512, 350)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.903242Z","iopub.execute_input":"2025-09-30T05:02:42.903729Z","iopub.status.idle":"2025-09-30T05:02:42.916720Z","shell.execute_reply.started":"2025-09-30T05:02:42.903706Z","shell.execute_reply":"2025-09-30T05:02:42.916222Z"}},"outputs":[],"execution_count":67},{"cell_type":"markdown","source":"# Layer Norm","metadata":{}},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    def __init__(self, eps: float = 1e-9):\n        super().__init__()\n        self.eps = eps\n        self.alpha = nn.Parameter(torch.ones(1))\n        self.bias = nn.Parameter(torch.zeros(1))\n\n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        std = x.std(dim=-1, keepdim=True)\n        return self.alpha * (x-mean) / (std+self.eps) + self.bias","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.918328Z","iopub.execute_input":"2025-09-30T05:02:42.918582Z","iopub.status.idle":"2025-09-30T05:02:42.928783Z","shell.execute_reply.started":"2025-09-30T05:02:42.918567Z","shell.execute_reply":"2025-09-30T05:02:42.928066Z"}},"outputs":[],"execution_count":68},{"cell_type":"markdown","source":"# FFW","metadata":{}},{"cell_type":"code","source":"class FeedForwardBlock(nn.Module):\n    \n    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n        super().__init__()\n        # First linear transformation\n        self.linear_1 = nn.Linear(d_model, d_ff) # W1 & b1\n        self.dropout = nn.Dropout(dropout) # Dropout to prevent overfitting\n        # Second linear transformation\n        self.linear_2 = nn.Linear(d_ff, d_model) # W2 & b2\n        \n    def forward(self, x):\n        # (Batch, seq_len, d_model) --> (batch, seq_len, d_ff) -->(batch, seq_len, d_model)\n        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.929527Z","iopub.execute_input":"2025-09-30T05:02:42.929745Z","iopub.status.idle":"2025-09-30T05:02:42.941030Z","shell.execute_reply.started":"2025-09-30T05:02:42.929719Z","shell.execute_reply":"2025-09-30T05:02:42.940395Z"}},"outputs":[],"execution_count":69},{"cell_type":"markdown","source":"# Multi Head Attention\n\n<center>\n    <img src = \"https://i.imgur.com/JqJVrsj.png\" width = 1556, height= 959>\n<p style = \"font-size: 16px;\n            font-family: 'Georgia', serif;\n            text-align: center;\n            margin-top: 10px;\"></p>\n</center>","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, n_heads: int, d_model: int):\n        super().__init__()\n        self.n_heads = n_heads\n        self.w_key = nn.Linear(d_model, d_model)\n        self.w_query = nn.Linear(d_model, d_model)\n        self.w_value = nn.Linear(d_model, d_model)\n        self.w_out = nn.Linear(d_model, d_model)\n\n    def attention(self, k, q, v, mask):\n        d_k = q.shape[-1]\n        affinities = (q @ k.transpose(-2, -1)) / math.sqrt(d_k)\n        if mask is not None:\n            affinities.masked_fill_(mask == 0, -1e9)\n        affinities = affinities.softmax(dim=-1)\n        value = affinities @ v\n        return value\n        \n\n    def forward(self, q, k, v, mask):\n        key = self.w_key(k)\n        query = self.w_query(q)\n        value = self.w_value(v)\n\n        # split embedding dim for each heads\n        new_d_model = config['d_model'] // self.n_heads\n        k_chunks = torch.split(key, new_d_model, dim=-1)\n        q_chunks = torch.split(query, new_d_model, dim=-1)\n        v_chunks = torch.split(value, new_d_model, dim=-1)\n\n        output_heads = []\n        for i in range(self.n_heads):\n            output_heads.append(self.attention(k_chunks[i], q_chunks[i], v_chunks[i], mask))\n\n        concat_out = torch.cat(output_heads, dim=-1)\n        return self.w_out(concat_out)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.941743Z","iopub.execute_input":"2025-09-30T05:02:42.941980Z","iopub.status.idle":"2025-09-30T05:02:42.954779Z","shell.execute_reply.started":"2025-09-30T05:02:42.941959Z","shell.execute_reply":"2025-09-30T05:02:42.954109Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"class ResidualConnection(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layernorm = LayerNorm()\n\n    def forward(self, x, sub_layer):\n        return x + sub_layer(self.layernorm(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.955522Z","iopub.execute_input":"2025-09-30T05:02:42.955745Z","iopub.status.idle":"2025-09-30T05:02:42.967015Z","shell.execute_reply.started":"2025-09-30T05:02:42.955723Z","shell.execute_reply":"2025-09-30T05:02:42.966411Z"}},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":"# Encoder\n<center>\n    <img src = \"https://www.researchgate.net/profile/Ehsan-Amjadian/publication/352239001/figure/fig1/AS:1033334390013952@1623377525434/Detailed-view-of-a-transformer-encoder-block-It-first-passes-the-input-through-an.jpg\" width = 400, height= 400>\n<p style = \"font-size: 16px;\n            font-family: 'Georgia', serif;\n            text-align: center;\n            margin-top: 10px;\">Encoder block. Source: <a href = \"https:///figure/Detailed-view-of-a-transformer-encoder-block-It-first-passes-the-input-through-an_fig1_352239001\">researchgate.net</a>.</p>\n</center>","metadata":{}},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.resnet_mha = ResidualConnection()\n        self.resnet_ffw = ResidualConnection()\n        self.mha = MultiHeadAttention(n_heads=config['n_heads'], d_model=config['d_model'])\n        self.ffw = FeedForwardBlock(d_model=config['d_model'], d_ff=config['dff'], dropout=config['p_drop'])\n\n    def forward(self, x, src_mask):\n        x = self.resnet_mha(x, lambda x : self.mha(x, x, x, src_mask))\n        x = self.resnet_ffw(x, lambda x : self.ffw(x))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.967775Z","iopub.execute_input":"2025-09-30T05:02:42.968372Z","iopub.status.idle":"2025-09-30T05:02:42.977108Z","shell.execute_reply.started":"2025-09-30T05:02:42.968355Z","shell.execute_reply":"2025-09-30T05:02:42.976581Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder_blocks = nn.ModuleList(\n            [EncoderBlock() for _ in range(config['encoder_layers'])]\n        )\n        \n    def forward(self, x, src_mask):\n        for block in self.encoder_blocks:\n            x = block(x, src_mask)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.977641Z","iopub.execute_input":"2025-09-30T05:02:42.977819Z","iopub.status.idle":"2025-09-30T05:02:42.991774Z","shell.execute_reply.started":"2025-09-30T05:02:42.977805Z","shell.execute_reply":"2025-09-30T05:02:42.991098Z"}},"outputs":[],"execution_count":73},{"cell_type":"markdown","source":"# Decoder\n\n<center>\n    <img src = \"https://res.cloudinary.com/edlitera/image/upload/c_fill,f_auto/v1680629118/blog/gz5ccspg3yvq4eo6xhrr\" width = 400, height= 400>\n<p style = \"font-size: 16px;\n            font-family: 'Georgia', serif;\n            text-align: center;\n            margin-top: 10px;\"></p>\n</center>","metadata":{}},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.resnet_blocks = nn.ModuleList([ResidualConnection() for _ in range(3)])\n        self.self_mha = MultiHeadAttention(n_heads=config['n_heads'], d_model=config['d_model'])\n        self.cross_mha = MultiHeadAttention(n_heads=config['n_heads'], d_model=config['d_model'])\n        self.ffw = FeedForwardBlock(d_model=config['d_model'], d_ff=config['dff'], dropout=config['p_drop'])\n\n    def forward(self, x, encoder_output, src_mask, tgt_mask):\n        x = self.resnet_blocks[0](x, lambda x: self.self_mha(x, x, x, tgt_mask))\n        x = self.resnet_blocks[1](x, lambda x: self.cross_mha(x, encoder_output, encoder_output, src_mask))\n        x = self.resnet_blocks[2](x, lambda x: self.ffw(x))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:42.992504Z","iopub.execute_input":"2025-09-30T05:02:42.992732Z","iopub.status.idle":"2025-09-30T05:02:43.003112Z","shell.execute_reply.started":"2025-09-30T05:02:42.992711Z","shell.execute_reply":"2025-09-30T05:02:43.002502Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.decoder_block = nn.ModuleList(\n            [DecoderBlock() for _ in range(config['decoder_layers'])]\n        )\n    def forward(self, x, encoder_output, src_mask, tgt_mask):\n        for layer in self.decoder_block:\n            x = layer(x, encoder_output, src_mask, tgt_mask)\n\n        return x ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:43.003719Z","iopub.execute_input":"2025-09-30T05:02:43.003887Z","iopub.status.idle":"2025-09-30T05:02:43.009535Z","shell.execute_reply.started":"2025-09-30T05:02:43.003869Z","shell.execute_reply":"2025-09-30T05:02:43.009027Z"}},"outputs":[],"execution_count":75},{"cell_type":"markdown","source":"# Transformer","metadata":{}},{"cell_type":"code","source":"class TranslationTransformer(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder_embeddings = TokenEmbeddings(config['d_model'], tokenizer_src.get_vocab_size())\n        self.encoder = Encoder()\n        self.decoder_embeddings = TokenEmbeddings(config['d_model'], tokenizer_tgt.get_vocab_size())\n        self.decoder = Decoder()\n        self.positional_encodings = PositionalEncoding(config['d_model'], config['seq_len'])\n        self.projection = nn.Linear(config['d_model'], tokenizer_tgt.get_vocab_size())\n\n    def encode(self, encoder_inp, src_mask):\n        encoder_embeddings = self.encoder_embeddings(encoder_inp)\n        encoder_embeddings = self.positional_encodings(encoder_embeddings)\n        encoder_output = self.encoder(encoder_embeddings, src_mask)\n        return encoder_output\n\n    def decode(self, encoder_output, decoder_inp, src_mask, tgt_mask):\n        decoder_embeddings = self.decoder_embeddings(decoder_inp)\n        decoder_embeddings = self.positional_encodings(decoder_embeddings)\n        decoder_output = self.decoder(decoder_embeddings, encoder_output, src_mask, tgt_mask)\n        output = torch.log_softmax(self.projection(decoder_output), dim = -1)\n        return output\n\n    def generate(self, encoder_inp, src_mask):\n        encoder_output = self.encode(encoder_inp, src_mask)\n\n        sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n        eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n        decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(encoder_inp).to(device)\n\n        while decoder_input.shape[1] < config['seq_len']:\n            decoder_output = self.decode(encoder_output, decoder_input, src_mask, causal_mask(decoder_input.shape[1]).type_as(src_mask))\n            output_token = torch.argmax(decoder_output[0, -1, :]) #greedy sampling\n            decoder_input = torch.cat([decoder_input, torch.empty(1,1).fill_(output_token).type_as(encoder_inp).to(device)], dim=1)\n\n            if output_token == eos_idx:\n                break\n\n        return decoder_input.squeeze(0)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:43.010081Z","iopub.execute_input":"2025-09-30T05:02:43.010307Z","iopub.status.idle":"2025-09-30T05:02:43.022760Z","shell.execute_reply.started":"2025-09-30T05:02:43.010291Z","shell.execute_reply":"2025-09-30T05:02:43.022089Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"a = torch.randn(3,4,5)\nprint(a[0, -1, :])\ntorch.argmax(a[0, -1, :])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:43.025091Z","iopub.execute_input":"2025-09-30T05:02:43.025350Z","iopub.status.idle":"2025-09-30T05:02:43.039214Z","shell.execute_reply.started":"2025-09-30T05:02:43.025334Z","shell.execute_reply":"2025-09-30T05:02:43.038484Z"}},"outputs":[{"name":"stdout","text":"tensor([ 0.3834,  0.1241,  0.6378, -0.4968, -2.0193])\n","output_type":"stream"},{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"tensor(2)"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, writer, num_examples=2):\n    model.eval() # Setting model to evaluation mode\n    count = 0 # Initializing counter to keep track of how many examples have been processed\n    \n    console_width = 80 # Fixed witdh for printed messages\n    \n    # Creating evaluation loop\n    with torch.no_grad(): # Ensuring that no gradients are computed during this process\n        for batch in validation_ds:\n            count += 1\n            encoder_input = batch['encoder_input'].to(device)\n            encoder_mask = batch['encoder_mask'].to(device)\n            \n            # Ensuring that the batch_size of the validation set is 1\n            assert encoder_input.size(0) ==  1, 'Batch size must be 1 for validation.'\n            \n            # Applying the 'greedy_decode' function to get the model's output for the source text of the input batch\n            model_out = model.generate(encoder_input, encoder_mask)\n            \n            # Retrieving source and target texts from the batch\n            source_text = batch['src_text'][0]\n            target_text = batch['tgt_text'][0] # True translation \n            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy()) # Decoded, human-readable model output\n            \n            # Printing results\n            print_msg('-'*console_width)\n            print_msg(f'SOURCE: {source_text}')\n            print_msg(f'TARGET: {target_text}')\n            print_msg(f'PREDICTED: {model_out_text}')\n            \n            # After two examples, we break the loop\n            if count == num_examples:\n                break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:43.039916Z","iopub.execute_input":"2025-09-30T05:02:43.040086Z","iopub.status.idle":"2025-09-30T05:02:43.048857Z","shell.execute_reply.started":"2025-09-30T05:02:43.040072Z","shell.execute_reply":"2025-09-30T05:02:43.048047Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:43.049621Z","iopub.execute_input":"2025-09-30T05:02:43.049824Z","iopub.status.idle":"2025-09-30T05:02:48.387840Z","shell.execute_reply.started":"2025-09-30T05:02:43.049810Z","shell.execute_reply":"2025-09-30T05:02:48.387076Z"}},"outputs":[{"name":"stdout","text":"Max length of source sentence: 309\nMax length of target sentence: 274\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"data = train_dataloader.dataset.__getitem__(100)\nprint(data['decoder_mask'].shape)\nprint(data['encoder_mask'].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:48.388552Z","iopub.execute_input":"2025-09-30T05:02:48.388800Z","iopub.status.idle":"2025-09-30T05:02:48.395405Z","shell.execute_reply.started":"2025-09-30T05:02:48.388777Z","shell.execute_reply":"2025-09-30T05:02:48.394743Z"}},"outputs":[{"name":"stdout","text":"torch.Size([350, 350])\ntorch.Size([1, 350])\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"model = TranslationTransformer().to(device)\n    \n# Initialize the parameters\nfor p in model.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:02:48.396020Z","iopub.execute_input":"2025-09-30T05:02:48.396207Z","iopub.status.idle":"2025-09-30T05:02:49.150059Z","shell.execute_reply.started":"2025-09-30T05:02:48.396191Z","shell.execute_reply":"2025-09-30T05:02:49.149305Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"def train_model():\n    writer = SummaryWriter(config['experiment_name'])\n    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps = 1e-9)\n    loss_fn = nn.CrossEntropyLoss(ignore_index = tokenizer_src.token_to_id('[PAD]'), label_smoothing = 0.1).to(device)\n\n    for epoch in range(config['num_epochs']):\n        batch_iterator = tqdm(train_dataloader, desc = f'Processing epoch {epoch:02d}')\n        for batch in batch_iterator:\n            model.train()\n            encoder_input = batch['encoder_input'].to(device)\n            decoder_input = batch['decoder_input'].to(device)\n            encoder_mask = batch['encoder_mask'].to(device)\n            decoder_mask = batch['decoder_mask'].to(device)\n\n            encoder_output = model.encode(encoder_input, encoder_mask)\n            decoder_output = model.decode(encoder_output, decoder_input, encoder_mask, decoder_mask)\n\n            label = batch['label'].to(device)\n            \n            loss = loss_fn(decoder_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n            \n            # Updating progress bar\n            batch_iterator.set_postfix({f\"loss\": f\"{loss.item():6.3f}\"})\n            \n            writer.add_scalar('train loss', loss.item())\n            writer.flush()\n            \n            # Performing backpropagation\n            loss.backward()\n            \n            # Updating parameters based on the gradients\n            optimizer.step()\n            \n            # Clearing the gradients to prepare for the next batch\n            optimizer.zero_grad()\n\n            run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: batch_iterator.write(msg), writer)\n         \n        # Writting current model state to the 'model_filename'\n        torch.save({\n            'epoch': epoch, # Current epoch\n            'model_state_dict': model.state_dict(),# Current model state\n            'optimizer_state_dict': optimizer.state_dict(), # Current optimizer state\n        }, f'checkpoint_{epoch}.pth')    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:32:31.620339Z","iopub.execute_input":"2025-09-30T05:32:31.620625Z","iopub.status.idle":"2025-09-30T05:32:31.627821Z","shell.execute_reply.started":"2025-09-30T05:32:31.620604Z","shell.execute_reply":"2025-09-30T05:32:31.627293Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"train_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:32:33.823069Z","iopub.execute_input":"2025-09-30T05:32:33.823772Z","iopub.status.idle":"2025-09-30T05:32:34.487858Z","shell.execute_reply.started":"2025-09-30T05:32:33.823745Z","shell.execute_reply":"2025-09-30T05:32:34.486565Z"}},"outputs":[{"name":"stderr","text":"Processing epoch 00:   0%|          | 0/3638 [00:00<?, ?it/s, loss=4.156]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1430278874.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/1241485799.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mrun_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_tgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Writting current model state to the 'model_filename'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/4001397399.py\u001b[0m in \u001b[0;36mrun_validation\u001b[0;34m(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, writer, num_examples)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Applying the 'greedy_decode' function to get the model's output for the source text of the input batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Retrieving source and target texts from the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/4276702701.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, encoder_inp, src_mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0moutput_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#greedy sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/4276702701.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, encoder_output, decoder_inp, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdecoder_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdecoder_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3590863303.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_output, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_block\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/956718772.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_output, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_mha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_mha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2605744101.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sub_layer)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/956718772.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_mha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_mha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3701559023.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moutput_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0moutput_heads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mconcat_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3701559023.py\u001b[0m in \u001b[0;36mattention\u001b[0;34m(self, k, q, v, mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0maffinities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0maffinities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0maffinities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maffinities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maffinities\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (350) at non-singleton dimension 2.  Target sizes: [1, 350, 1].  Tensor sizes: [1, 1, 350]"],"ename":"RuntimeError","evalue":"The expanded size of the tensor (1) must match the existing size (350) at non-singleton dimension 2.  Target sizes: [1, 350, 1].  Tensor sizes: [1, 1, 350]","output_type":"error"}],"execution_count":85},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}