{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19678caa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:37.681440Z",
     "iopub.status.busy": "2025-09-30T08:59:37.681137Z",
     "iopub.status.idle": "2025-09-30T08:59:58.084577Z",
     "shell.execute_reply": "2025-09-30T08:59:58.083761Z"
    },
    "papermill": {
     "duration": 20.411485,
     "end_time": "2025-09-30T08:59:58.085995",
     "exception": false,
     "start_time": "2025-09-30T08:59:37.674510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 08:59:43.889987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759222784.095171      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759222784.153508      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Math\n",
    "import math\n",
    "\n",
    "# HuggingFace libraries \n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "# Pathlib \n",
    "from pathlib import Path\n",
    "\n",
    "# typing\n",
    "from typing import Any\n",
    "\n",
    "# Library for progress bars in loops\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Importing library of warnings\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8086d45",
   "metadata": {
    "papermill": {
     "duration": 0.004411,
     "end_time": "2025-09-30T08:59:58.095799",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.091388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be72c8ea",
   "metadata": {
    "papermill": {
     "duration": 0.004316,
     "end_time": "2025-09-30T08:59:58.104743",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.100427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Image](https://shreyansh26.github.io/assets/img/posts_images/attention/arch.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fc7098",
   "metadata": {
    "papermill": {
     "duration": 0.004324,
     "end_time": "2025-09-30T08:59:58.113614",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.109290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d0128",
   "metadata": {
    "papermill": {
     "duration": 0.004329,
     "end_time": "2025-09-30T08:59:58.122450",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.118121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Tokenizer](https://i.ytimg.com/vi/hL4ZnAWSyuU/sddefault.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a01de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.132805Z",
     "iopub.status.busy": "2025-09-30T08:59:58.132103Z",
     "iopub.status.idle": "2025-09-30T08:59:58.137051Z",
     "shell.execute_reply": "2025-09-30T08:59:58.136512Z"
    },
    "papermill": {
     "duration": 0.011108,
     "end_time": "2025-09-30T08:59:58.138020",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.126912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_tokenizer(config, ds, lang):\n",
    "    \n",
    "    # Crating a file path for the tokenizer \n",
    "    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n",
    "    \n",
    "    # Checking if Tokenizer already exists\n",
    "    if not Path.exists(tokenizer_path): \n",
    "        \n",
    "        # If it doesn't exist, we create a new one\n",
    "        tokenizer = Tokenizer(WordLevel(unk_token = '[UNK]')) # Initializing a new world-level tokenizer\n",
    "        tokenizer.pre_tokenizer = Whitespace() # We will split the text into tokens based on whitespace\n",
    "        \n",
    "        # Creating a trainer for the new tokenizer\n",
    "        trainer = WordLevelTrainer(special_tokens = [\"[UNK]\", \"[PAD]\", \n",
    "                                                     \"[SOS]\", \"[EOS]\"], min_frequency = 2) # Defining Word Level strategy and special tokens\n",
    "        \n",
    "        # Training new tokenizer on sentences from the dataset and language specified \n",
    "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer = trainer)\n",
    "        tokenizer.save(str(tokenizer_path)) # Saving trained tokenizer to the file path specified at the beginning of the function\n",
    "    else:\n",
    "        tokenizer = Tokenizer.from_file(str(tokenizer_path)) # If the tokenizer already exist, we load it\n",
    "    return tokenizer # Returns the loaded tokenizer or the trained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93aa35d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.148367Z",
     "iopub.status.busy": "2025-09-30T08:59:58.148152Z",
     "iopub.status.idle": "2025-09-30T08:59:58.152282Z",
     "shell.execute_reply": "2025-09-30T08:59:58.151633Z"
    },
    "papermill": {
     "duration": 0.010177,
     "end_time": "2025-09-30T08:59:58.153297",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.143120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    return{\n",
    "        'batch_size': 8,\n",
    "        'num_epochs': 20,\n",
    "        'lr': 10**-4,\n",
    "        'seq_len': 350,\n",
    "        'd_model': 512, # Dimensions of the embeddings in the Transformer. 512 like in the \"Attention Is All You Need\" paper.\n",
    "        'lang_src': 'en',\n",
    "        'lang_tgt': 'it',\n",
    "        'model_folder': 'weights',\n",
    "        'model_basename': 'translation_model_',\n",
    "        'preload': None,\n",
    "        'tokenizer_file': 'tokenizer_{0}.json',\n",
    "        'experiment_name': 'runs/translation_model',\n",
    "        'encoder_layers': 6,\n",
    "        'decoder_layers': 6,\n",
    "        'p_drop': 0.1,\n",
    "        'dff': 2048,\n",
    "        'n_heads': 8\n",
    "    }\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ca28e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.163047Z",
     "iopub.status.busy": "2025-09-30T08:59:58.162840Z",
     "iopub.status.idle": "2025-09-30T08:59:58.170104Z",
     "shell.execute_reply": "2025-09-30T08:59:58.169451Z"
    },
    "papermill": {
     "duration": 0.013298,
     "end_time": "2025-09-30T08:59:58.171139",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.157841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_sentences(ds, lang):\n",
    "    for pair in ds:\n",
    "        yield pair['translation'][lang]\n",
    "        \n",
    "tokenizer_src = None\n",
    "tokenizer_tgt = None\n",
    "train_ds = None\n",
    "def get_ds(config):\n",
    "    \n",
    "    # Loading the train portion of the OpusBooks dataset.\n",
    "    # The Language pairs will be defined in the 'config' dictionary we will build later\n",
    "    ds_raw = load_dataset('opus_books', f'{config[\"lang_src\"]}-{config[\"lang_tgt\"]}', split = 'train') \n",
    "    \n",
    "    # Building or loading tokenizer for both the source and target languages \n",
    "    tokenizer_src = build_tokenizer(config, ds_raw, config['lang_src'])\n",
    "    tokenizer_tgt = build_tokenizer(config, ds_raw, config['lang_tgt'])\n",
    "    \n",
    "    # Splitting the dataset for training and validation \n",
    "    train_ds_size = int(0.9 * len(ds_raw)) # 90% for training\n",
    "    val_ds_size = len(ds_raw) - train_ds_size # 10% for validation\n",
    "    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size]) # Randomly splitting the dataset\n",
    "                                    \n",
    "    # Processing data with the BilingualDataset class, which we will define below\n",
    "    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
    "    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
    "                                    \n",
    "    # Iterating over the entire dataset and printing the maximum length found in the sentences of both the source and target languages\n",
    "    max_len_src = 0\n",
    "    max_len_tgt = 0\n",
    "    for pair in ds_raw:\n",
    "        src_ids = tokenizer_src.encode(pair['translation'][config['lang_src']]).ids\n",
    "        tgt_ids = tokenizer_src.encode(pair['translation'][config['lang_tgt']]).ids\n",
    "        max_len_src = max(max_len_src, len(src_ids))\n",
    "        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
    "        \n",
    "    print(f'Max length of source sentence: {max_len_src}')\n",
    "    print(f'Max length of target sentence: {max_len_tgt}')\n",
    "    \n",
    "    # Creating dataloaders for the training and validadion sets\n",
    "    # Dataloaders are used to iterate over the dataset in batches during training and validation\n",
    "    train_dataloader = DataLoader(train_ds, batch_size = config['batch_size'], shuffle = True) # Batch size will be defined in the config dictionary\n",
    "    val_dataloader = DataLoader(val_ds, batch_size = 1, shuffle = True)\n",
    "    \n",
    "    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt # Returning the DataLoader objects and tokenizers\n",
    "\n",
    "def casual_mask(size):\n",
    "        # Creating a square matrix of dimensions 'size x size' filled with ones\n",
    "        mask = torch.triu(torch.ones(1, size, size), diagonal = 1).type(torch.int)\n",
    "        return mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a370087f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.181055Z",
     "iopub.status.busy": "2025-09-30T08:59:58.180851Z",
     "iopub.status.idle": "2025-09-30T08:59:58.190997Z",
     "shell.execute_reply": "2025-09-30T08:59:58.190502Z"
    },
    "papermill": {
     "duration": 0.016377,
     "end_time": "2025-09-30T08:59:58.191999",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.175622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BilingualDataset(Dataset):\n",
    "    \n",
    "    # This takes in the dataset contaning sentence pairs, the tokenizers for target and source languages, and the strings of source and target languages\n",
    "    # 'seq_len' defines the sequence length for both languages\n",
    "    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.ds = ds\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.tokenizer_tgt = tokenizer_tgt\n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        \n",
    "        # Defining special tokens by using the target language tokenizer\n",
    "        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n",
    "        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n",
    "        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
    "\n",
    "        \n",
    "    # Total number of instances in the dataset (some pairs are larger than others)\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    # Using the index to retrive source and target texts\n",
    "    def __getitem__(self, index: Any) -> Any:\n",
    "        src_target_pair = self.ds[index]\n",
    "        src_text = src_target_pair['translation'][self.src_lang]\n",
    "        tgt_text = src_target_pair['translation'][self.tgt_lang]\n",
    "        \n",
    "        # Tokenizing source and target texts \n",
    "        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n",
    "        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
    "        \n",
    "        # Computing how many padding tokens need to be added to the tokenized texts \n",
    "        # Source tokens\n",
    "        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2 # Subtracting the two '[EOS]' and '[SOS]' special tokens\n",
    "        # Target tokens\n",
    "        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1 # Subtracting the '[SOS]' special token\n",
    "        \n",
    "        # If the texts exceed the 'seq_len' allowed, it will raise an error. This means that one of the sentences in the pair is too long to be processed\n",
    "        # given the current sequence length limit (this will be defined in the config dictionary below)\n",
    "        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n",
    "            raise ValueError('Sentence is too long')\n",
    "         \n",
    "        # Building the encoder input tensor by combining several elements\n",
    "        encoder_input = torch.cat(\n",
    "            [\n",
    "            self.sos_token, # inserting the '[SOS]' token\n",
    "            torch.tensor(enc_input_tokens, dtype = torch.int64), # Inserting the tokenized source text\n",
    "            self.eos_token, # Inserting the '[EOS]' token\n",
    "            torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype = torch.int64) # Addind padding tokens\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Building the decoder input tensor by combining several elements\n",
    "        decoder_input = torch.cat(\n",
    "            [\n",
    "                self.sos_token, # inserting the '[SOS]' token \n",
    "                torch.tensor(dec_input_tokens, dtype = torch.int64), # Inserting the tokenized target text\n",
    "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype = torch.int64) # Addind padding tokens\n",
    "            ]\n",
    "        \n",
    "        )\n",
    "        \n",
    "        # Creating a label tensor, the expected output for training the model\n",
    "        label = torch.cat(\n",
    "            [\n",
    "                torch.tensor(dec_input_tokens, dtype = torch.int64), # Inserting the tokenized target text\n",
    "                self.eos_token, # Inserting the '[EOS]' token \n",
    "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype = torch.int64) # Adding padding tokens\n",
    "                \n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Ensuring that the length of each tensor above is equal to the defined 'seq_len'\n",
    "        assert encoder_input.size(0) == self.seq_len\n",
    "        assert decoder_input.size(0) == self.seq_len\n",
    "        assert label.size(0) == self.seq_len\n",
    "        \n",
    "        return {\n",
    "            'encoder_input': encoder_input,\n",
    "            'decoder_input': decoder_input, \n",
    "            'encoder_mask': (encoder_input != self.pad_token).unsqueeze(0).int(),\n",
    "            'decoder_mask': (decoder_input != self.pad_token).unsqueeze(0).int() & (causal_mask(decoder_input.size(0)).squeeze(0)), \n",
    "            'label': label,\n",
    "            'src_text': src_text,\n",
    "            'tgt_text': tgt_text\n",
    "        }    \n",
    "\n",
    "def causal_mask(size):\n",
    "        # Creating a square matrix of dimensions 'size x size' filled with ones\n",
    "        mask = torch.triu(torch.ones(1, size, size), diagonal = 1).type(torch.int)\n",
    "        return mask == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8312f0",
   "metadata": {
    "papermill": {
     "duration": 0.004268,
     "end_time": "2025-09-30T08:59:58.200709",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.196441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67586c65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.210409Z",
     "iopub.status.busy": "2025-09-30T08:59:58.210185Z",
     "iopub.status.idle": "2025-09-30T08:59:58.213881Z",
     "shell.execute_reply": "2025-09-30T08:59:58.213384Z"
    },
    "papermill": {
     "duration": 0.009638,
     "end_time": "2025-09-30T08:59:58.214917",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.205279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embeddings = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embeddings(x) * math.sqrt(self.d_model) # Normalizing the variance of the embedding\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81dade8",
   "metadata": {
    "papermill": {
     "duration": 0.004351,
     "end_time": "2025-09-30T08:59:58.223729",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.219378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Positional Encoding\n",
    "\n",
    "<p style=\"\n",
    "    margin-bottom: 5; \n",
    "    font-size: 22px;\n",
    "    font-weight: 300;\n",
    "    font-family: 'Helvetica Neue', sans-serif;\n",
    "    color: #000000; \n",
    "  \">\n",
    "    \\begin{equation}\n",
    "    \\text{Even Indices } (2i): \\quad \\text{PE(pos, } 2i) = \\sin\\left(\\frac{\\text{pos}}{10000^{2i / d_{model}}}\\right)\n",
    "    \\end{equation}\n",
    "</p>\n",
    "\n",
    "<p style=\"\n",
    "    margin-bottom: 5; \n",
    "    font-size: 22px;\n",
    "    font-weight: 300;\n",
    "    font-family: 'Helvetica Neue', sans-serif;\n",
    "    color: #000000; \n",
    "  \">\n",
    "    \\begin{equation}\n",
    "    \\text{Odd Indices } (2i + 1): \\quad \\text{PE(pos, } 2i + 1) = \\cos\\left(\\frac{\\text{pos}}{10000^{2i / d_{model}}}\\right)\n",
    "    \\end{equation}\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f52022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.233310Z",
     "iopub.status.busy": "2025-09-30T08:59:58.233079Z",
     "iopub.status.idle": "2025-09-30T08:59:58.237794Z",
     "shell.execute_reply": "2025-09-30T08:59:58.237354Z"
    },
    "papermill": {
     "duration": 0.010597,
     "end_time": "2025-09-30T08:59:58.238702",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.228105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, seq_len: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        encodings = torch.zeros(seq_len, d_model)\n",
    "        pos = torch.arange(0, seq_len, dtype = torch.float).unsqueeze(1) # [seq_len, 1]\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        encodings[:, 0::2] = torch.sin(pos * div_term)\n",
    "        encodings[:, 1::2] = torch.cos(pos * div_term)\n",
    "        encodings = encodings.unsqueeze(0) # add a batch dimension\n",
    "        self.register_buffer('encodings', encodings) # Buffer is a tensor not considered as a model parameter\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + (self.encodings[:, :x.shape[1], :]).requires_grad_(False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db01767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.248685Z",
     "iopub.status.busy": "2025-09-30T08:59:58.248482Z",
     "iopub.status.idle": "2025-09-30T08:59:58.332617Z",
     "shell.execute_reply": "2025-09-30T08:59:58.331936Z"
    },
    "papermill": {
     "duration": 0.090385,
     "end_time": "2025-09-30T08:59:58.333697",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.243312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "posm = PositionalEncoding(512, 350)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd917a25",
   "metadata": {
    "papermill": {
     "duration": 0.004392,
     "end_time": "2025-09-30T08:59:58.342703",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.338311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40dd67ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.352649Z",
     "iopub.status.busy": "2025-09-30T08:59:58.352395Z",
     "iopub.status.idle": "2025-09-30T08:59:58.356897Z",
     "shell.execute_reply": "2025-09-30T08:59:58.356370Z"
    },
    "papermill": {
     "duration": 0.010816,
     "end_time": "2025-09-30T08:59:58.357976",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.347160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, eps: float = 1e-9):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        std = x.std(dim=-1, keepdim=True)\n",
    "        return self.alpha * (x-mean) / (std+self.eps) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e5f804",
   "metadata": {
    "papermill": {
     "duration": 0.004366,
     "end_time": "2025-09-30T08:59:58.367258",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.362892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "927aaa71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.377669Z",
     "iopub.status.busy": "2025-09-30T08:59:58.377106Z",
     "iopub.status.idle": "2025-09-30T08:59:58.381668Z",
     "shell.execute_reply": "2025-09-30T08:59:58.381144Z"
    },
    "papermill": {
     "duration": 0.010958,
     "end_time": "2025-09-30T08:59:58.382703",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.371745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        # First linear transformation\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff) # W1 & b1\n",
    "        self.dropout = nn.Dropout(dropout) # Dropout to prevent overfitting\n",
    "        # Second linear transformation\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model) # W2 & b2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (Batch, seq_len, d_model) --> (batch, seq_len, d_ff) -->(batch, seq_len, d_model)\n",
    "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e908f5e",
   "metadata": {
    "papermill": {
     "duration": 0.00427,
     "end_time": "2025-09-30T08:59:58.391425",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.387155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multi Head Attention\n",
    "\n",
    "<center>\n",
    "    <img src = \"https://i.imgur.com/JqJVrsj.png\" width = 1556, height= 959>\n",
    "<p style = \"font-size: 16px;\n",
    "            font-family: 'Georgia', serif;\n",
    "            text-align: center;\n",
    "            margin-top: 10px;\"></p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56bc4de8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.401505Z",
     "iopub.status.busy": "2025-09-30T08:59:58.401212Z",
     "iopub.status.idle": "2025-09-30T08:59:58.408644Z",
     "shell.execute_reply": "2025-09-30T08:59:58.408117Z"
    },
    "papermill": {
     "duration": 0.013845,
     "end_time": "2025-09-30T08:59:58.409708",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.395863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.w_key = nn.Linear(d_model, d_model)\n",
    "        self.w_query = nn.Linear(d_model, d_model)\n",
    "        self.w_value = nn.Linear(d_model, d_model)\n",
    "        self.w_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def attention(self, k, q, v, mask):\n",
    "        d_k = q.shape[-1]\n",
    "        affinities = (q @ k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            affinities.masked_fill_(mask == 0, -1e9)\n",
    "        affinities = affinities.softmax(dim=-1)\n",
    "        value = affinities @ v\n",
    "        return value\n",
    "        \n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        key = self.w_key(k)\n",
    "        query = self.w_query(q)\n",
    "        value = self.w_value(v)\n",
    "\n",
    "        # split embedding dim for each heads\n",
    "        new_d_model = config['d_model'] // self.n_heads\n",
    "        k_chunks = torch.split(key, new_d_model, dim=-1)\n",
    "        q_chunks = torch.split(query, new_d_model, dim=-1)\n",
    "        v_chunks = torch.split(value, new_d_model, dim=-1)\n",
    "\n",
    "        output_heads = []\n",
    "        for i in range(self.n_heads):\n",
    "            output_heads.append(self.attention(k_chunks[i], q_chunks[i], v_chunks[i], mask))\n",
    "\n",
    "        concat_out = torch.cat(output_heads, dim=-1)\n",
    "        return self.w_out(concat_out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb564584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.419804Z",
     "iopub.status.busy": "2025-09-30T08:59:58.419598Z",
     "iopub.status.idle": "2025-09-30T08:59:58.423250Z",
     "shell.execute_reply": "2025-09-30T08:59:58.422597Z"
    },
    "papermill": {
     "duration": 0.009935,
     "end_time": "2025-09-30T08:59:58.424382",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.414447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layernorm = LayerNorm()\n",
    "\n",
    "    def forward(self, x, sub_layer):\n",
    "        return x + sub_layer(self.layernorm(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2ac78c",
   "metadata": {
    "papermill": {
     "duration": 0.004356,
     "end_time": "2025-09-30T08:59:58.433271",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.428915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encoder\n",
    "<center>\n",
    "    <img src = \"https://www.researchgate.net/profile/Ehsan-Amjadian/publication/352239001/figure/fig1/AS:1033334390013952@1623377525434/Detailed-view-of-a-transformer-encoder-block-It-first-passes-the-input-through-an.jpg\" width = 400, height= 400>\n",
    "<p style = \"font-size: 16px;\n",
    "            font-family: 'Georgia', serif;\n",
    "            text-align: center;\n",
    "            margin-top: 10px;\">Encoder block. Source: <a href = \"https:///figure/Detailed-view-of-a-transformer-encoder-block-It-first-passes-the-input-through-an_fig1_352239001\">researchgate.net</a>.</p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c243ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.444072Z",
     "iopub.status.busy": "2025-09-30T08:59:58.443678Z",
     "iopub.status.idle": "2025-09-30T08:59:58.448155Z",
     "shell.execute_reply": "2025-09-30T08:59:58.447497Z"
    },
    "papermill": {
     "duration": 0.010717,
     "end_time": "2025-09-30T08:59:58.449272",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.438555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet_mha = ResidualConnection()\n",
    "        self.resnet_ffw = ResidualConnection()\n",
    "        self.mha = MultiHeadAttention(n_heads=config['n_heads'], d_model=config['d_model'])\n",
    "        self.ffw = FeedForwardBlock(d_model=config['d_model'], d_ff=config['dff'], dropout=config['p_drop'])\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.resnet_mha(x, lambda x : self.mha(x, x, x, src_mask))\n",
    "        x = self.resnet_ffw(x, lambda x : self.ffw(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93dfd177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.459218Z",
     "iopub.status.busy": "2025-09-30T08:59:58.458676Z",
     "iopub.status.idle": "2025-09-30T08:59:58.462892Z",
     "shell.execute_reply": "2025-09-30T08:59:58.462268Z"
    },
    "papermill": {
     "duration": 0.010179,
     "end_time": "2025-09-30T08:59:58.463922",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.453743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "            [EncoderBlock() for _ in range(config['encoder_layers'])]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, src_mask):\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x, src_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f043f293",
   "metadata": {
    "papermill": {
     "duration": 0.004648,
     "end_time": "2025-09-30T08:59:58.473035",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.468387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Decoder\n",
    "\n",
    "<center>\n",
    "    <img src = \"https://res.cloudinary.com/edlitera/image/upload/c_fill,f_auto/v1680629118/blog/gz5ccspg3yvq4eo6xhrr\" width = 400, height= 400>\n",
    "<p style = \"font-size: 16px;\n",
    "            font-family: 'Georgia', serif;\n",
    "            text-align: center;\n",
    "            margin-top: 10px;\"></p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c90d3be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.483345Z",
     "iopub.status.busy": "2025-09-30T08:59:58.482709Z",
     "iopub.status.idle": "2025-09-30T08:59:58.487990Z",
     "shell.execute_reply": "2025-09-30T08:59:58.487365Z"
    },
    "papermill": {
     "duration": 0.01139,
     "end_time": "2025-09-30T08:59:58.489018",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.477628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet_blocks = nn.ModuleList([ResidualConnection() for _ in range(3)])\n",
    "        self.self_mha = MultiHeadAttention(n_heads=config['n_heads'], d_model=config['d_model'])\n",
    "        self.cross_mha = MultiHeadAttention(n_heads=config['n_heads'], d_model=config['d_model'])\n",
    "        self.ffw = FeedForwardBlock(d_model=config['d_model'], d_ff=config['dff'], dropout=config['p_drop'])\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        x = self.resnet_blocks[0](x, lambda x: self.self_mha(x, x, x, tgt_mask))\n",
    "        x = self.resnet_blocks[1](x, lambda x: self.cross_mha(x, encoder_output, encoder_output, src_mask))\n",
    "        x = self.resnet_blocks[2](x, lambda x: self.ffw(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "568beb98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.498881Z",
     "iopub.status.busy": "2025-09-30T08:59:58.498686Z",
     "iopub.status.idle": "2025-09-30T08:59:58.502694Z",
     "shell.execute_reply": "2025-09-30T08:59:58.502035Z"
    },
    "papermill": {
     "duration": 0.010171,
     "end_time": "2025-09-30T08:59:58.503731",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.493560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.decoder_block = nn.ModuleList(\n",
    "            [DecoderBlock() for _ in range(config['decoder_layers'])]\n",
    "        )\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        for layer in self.decoder_block:\n",
    "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5fe210",
   "metadata": {
    "papermill": {
     "duration": 0.004302,
     "end_time": "2025-09-30T08:59:58.512505",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.508203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea99236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.522029Z",
     "iopub.status.busy": "2025-09-30T08:59:58.521851Z",
     "iopub.status.idle": "2025-09-30T08:59:58.529660Z",
     "shell.execute_reply": "2025-09-30T08:59:58.528989Z"
    },
    "papermill": {
     "duration": 0.013751,
     "end_time": "2025-09-30T08:59:58.530687",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.516936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TranslationTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder_embeddings = TokenEmbeddings(config['d_model'], tokenizer_src.get_vocab_size())\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder_embeddings = TokenEmbeddings(config['d_model'], tokenizer_tgt.get_vocab_size())\n",
    "        self.decoder = Decoder()\n",
    "        self.positional_encodings = PositionalEncoding(config['d_model'], config['seq_len'])\n",
    "        self.projection = nn.Linear(config['d_model'], tokenizer_tgt.get_vocab_size())\n",
    "\n",
    "    def encode(self, encoder_inp, src_mask):\n",
    "        encoder_embeddings = self.encoder_embeddings(encoder_inp)\n",
    "        encoder_embeddings = self.positional_encodings(encoder_embeddings)\n",
    "        encoder_output = self.encoder(encoder_embeddings, src_mask)\n",
    "        return encoder_output\n",
    "\n",
    "    def decode(self, encoder_output, decoder_inp, src_mask, tgt_mask):\n",
    "        decoder_embeddings = self.decoder_embeddings(decoder_inp)\n",
    "        decoder_embeddings = self.positional_encodings(decoder_embeddings)\n",
    "        decoder_output = self.decoder(decoder_embeddings, encoder_output, src_mask, tgt_mask)\n",
    "        output = torch.log_softmax(self.projection(decoder_output), dim = -1)\n",
    "        return output\n",
    "\n",
    "    def generate(self, encoder_inp, src_mask):\n",
    "        encoder_output = self.encode(encoder_inp, src_mask)\n",
    "\n",
    "        sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n",
    "        eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n",
    "        decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(encoder_inp).to(device)\n",
    "\n",
    "        while decoder_input.shape[1] < config['seq_len']:\n",
    "            decoder_output = self.decode(encoder_output, decoder_input, src_mask, causal_mask(decoder_input.shape[1]).type_as(src_mask))\n",
    "            output_token = torch.argmax(decoder_output[0, -1, :]) #greedy sampling\n",
    "            decoder_input = torch.cat([decoder_input, torch.empty(1,1).fill_(output_token).type_as(encoder_inp).to(device)], dim=1)\n",
    "\n",
    "            if output_token == eos_idx:\n",
    "                break\n",
    "\n",
    "        return decoder_input.squeeze(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf166001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.540536Z",
     "iopub.status.busy": "2025-09-30T08:59:58.540358Z",
     "iopub.status.idle": "2025-09-30T08:59:58.582031Z",
     "shell.execute_reply": "2025-09-30T08:59:58.581464Z"
    },
    "papermill": {
     "duration": 0.047793,
     "end_time": "2025-09-30T08:59:58.583044",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.535251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3509, -0.6808,  0.7474, -0.2319,  0.3486])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,4,5)\n",
    "print(a[0, -1, :])\n",
    "torch.argmax(a[0, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "489fb4bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.593152Z",
     "iopub.status.busy": "2025-09-30T08:59:58.592956Z",
     "iopub.status.idle": "2025-09-30T08:59:58.597931Z",
     "shell.execute_reply": "2025-09-30T08:59:58.597470Z"
    },
    "papermill": {
     "duration": 0.01114,
     "end_time": "2025-09-30T08:59:58.598910",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.587770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, writer, num_examples=2):\n",
    "    model.eval() # Setting model to evaluation mode\n",
    "    count = 0 # Initializing counter to keep track of how many examples have been processed\n",
    "    \n",
    "    console_width = 80 # Fixed witdh for printed messages\n",
    "    \n",
    "    # Creating evaluation loop\n",
    "    with torch.no_grad(): # Ensuring that no gradients are computed during this process\n",
    "        for batch in validation_ds:\n",
    "            count += 1\n",
    "            encoder_input = batch['encoder_input'].to(device)\n",
    "            encoder_mask = batch['encoder_mask'].to(device)\n",
    "            \n",
    "            # Ensuring that the batch_size of the validation set is 1\n",
    "            assert encoder_input.size(0) ==  1, 'Batch size must be 1 for validation.'\n",
    "            \n",
    "            # Applying the 'greedy_decode' function to get the model's output for the source text of the input batch\n",
    "            model_out = model.generate(encoder_input, encoder_mask)\n",
    "            \n",
    "            # Retrieving source and target texts from the batch\n",
    "            source_text = batch['src_text'][0]\n",
    "            target_text = batch['tgt_text'][0] # True translation \n",
    "            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy()) # Decoded, human-readable model output\n",
    "            \n",
    "            # Printing results\n",
    "            print_msg('-'*console_width)\n",
    "            print_msg(f'SOURCE: {source_text}')\n",
    "            print_msg(f'TARGET: {target_text}')\n",
    "            print_msg(f'PREDICTED: {model_out_text}')\n",
    "            \n",
    "            # After two examples, we break the loop\n",
    "            if count == num_examples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2418c134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T08:59:58.608986Z",
     "iopub.status.busy": "2025-09-30T08:59:58.608791Z",
     "iopub.status.idle": "2025-09-30T09:00:08.145812Z",
     "shell.execute_reply": "2025-09-30T09:00:08.144961Z"
    },
    "papermill": {
     "duration": 9.543325,
     "end_time": "2025-09-30T09:00:08.147002",
     "exception": false,
     "start_time": "2025-09-30T08:59:58.603677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678d6f82047340d3b59210d7153898d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77af2b96b86c43aa9b0c3a9c372f679f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "en-it/train-00000-of-00001.parquet:   0%|          | 0.00/5.73M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2ec21996ab43b7aaf602929cd99e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 309\n",
      "Max length of target sentence: 274\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb94a3b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T09:00:08.158413Z",
     "iopub.status.busy": "2025-09-30T09:00:08.158165Z",
     "iopub.status.idle": "2025-09-30T09:00:08.170417Z",
     "shell.execute_reply": "2025-09-30T09:00:08.169724Z"
    },
    "papermill": {
     "duration": 0.01893,
     "end_time": "2025-09-30T09:00:08.171528",
     "exception": false,
     "start_time": "2025-09-30T09:00:08.152598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([350, 350])\n",
      "torch.Size([1, 350])\n"
     ]
    }
   ],
   "source": [
    "data = train_dataloader.dataset.__getitem__(100)\n",
    "print(data['decoder_mask'].shape)\n",
    "print(data['encoder_mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df2dd265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T09:00:08.182335Z",
     "iopub.status.busy": "2025-09-30T09:00:08.182099Z",
     "iopub.status.idle": "2025-09-30T09:00:09.138087Z",
     "shell.execute_reply": "2025-09-30T09:00:09.137512Z"
    },
    "papermill": {
     "duration": 0.962923,
     "end_time": "2025-09-30T09:00:09.139492",
     "exception": false,
     "start_time": "2025-09-30T09:00:08.176569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = TranslationTransformer().to(device)\n",
    "    \n",
    "# Initialize the parameters\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6f5d817",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T09:00:09.150710Z",
     "iopub.status.busy": "2025-09-30T09:00:09.150472Z",
     "iopub.status.idle": "2025-09-30T09:00:09.158766Z",
     "shell.execute_reply": "2025-09-30T09:00:09.158253Z"
    },
    "papermill": {
     "duration": 0.014872,
     "end_time": "2025-09-30T09:00:09.159745",
     "exception": false,
     "start_time": "2025-09-30T09:00:09.144873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    writer = SummaryWriter(config['experiment_name'])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps = 1e-9)\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index = tokenizer_src.token_to_id('[PAD]'), label_smoothing = 0.1).to(device)\n",
    "\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        batch_iterator = tqdm(train_dataloader, desc = f'Processing epoch {epoch:02d}')\n",
    "        for batch in batch_iterator:\n",
    "            model.train()\n",
    "            encoder_input = batch['encoder_input'].to(device)\n",
    "            decoder_input = batch['decoder_input'].to(device)\n",
    "            encoder_mask = batch['encoder_mask'].to(device)\n",
    "            decoder_mask = batch['decoder_mask'].to(device)\n",
    "\n",
    "            encoder_output = model.encode(encoder_input, encoder_mask)\n",
    "            decoder_output = model.decode(encoder_output, decoder_input, encoder_mask, decoder_mask)\n",
    "\n",
    "            label = batch['label'].to(device)\n",
    "            \n",
    "            loss = loss_fn(decoder_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
    "            \n",
    "            # Updating progress bar\n",
    "            batch_iterator.set_postfix({f\"loss\": f\"{loss.item():6.3f}\"})\n",
    "            \n",
    "            writer.add_scalar('train loss', loss.item())\n",
    "            writer.flush()\n",
    "            \n",
    "            # Performing backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Updating parameters based on the gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Clearing the gradients to prepare for the next batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: batch_iterator.write(msg), writer)\n",
    "         \n",
    "        # Writting current model state to the 'model_filename'\n",
    "        torch.save({\n",
    "            'epoch': epoch, # Current epoch\n",
    "            'model_state_dict': model.state_dict(),# Current model state\n",
    "            'optimizer_state_dict': optimizer.state_dict(), # Current optimizer state\n",
    "        }, f'checkpoint_{epoch}.pth')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cd554d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T09:00:09.170631Z",
     "iopub.status.busy": "2025-09-30T09:00:09.170019Z",
     "iopub.status.idle": "2025-09-30T17:53:03.076131Z",
     "shell.execute_reply": "2025-09-30T17:53:03.075527Z"
    },
    "papermill": {
     "duration": 31973.912797,
     "end_time": "2025-09-30T17:53:03.077558",
     "exception": false,
     "start_time": "2025-09-30T09:00:09.164761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 00: 100%|| 3638/3638 [26:31<00:00,  2.29it/s, loss=5.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Karenin, ready to deliver his speech, stood pressing his interlaced fingers together, trying whether some of them would not crack again.\n",
      "TARGET: Aleksej Aleksandrovic, pronto per il suo discorso, stava in piedi, stringendo le dita incrociate e provando se in qualche giuntura volessero ancora scricchiolare.\n",
      "PREDICTED: Aleksej Aleksandrovic , in fondo a , , , se non si trovava mai , se non si trovava a far pi .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: It is not I who am guilty,' he said to himself, 'but it is she. She does not concern me.\n",
      "TARGET: Non sono io il colpevole  diceva a se stesso  ma lei.\n",
      "PREDICTED: Non  vero che io sono venuto a conoscere  disse , ma non  vero .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 01: 100%|| 3638/3638 [26:33<00:00,  2.28it/s, loss=4.341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Yes, yes!' he cried in a shrill voice. 'I will take the disgrace, and even give up my son... but... but had we not better let it alone?\n",
      "TARGET:  S, s  grid con voce stridula  prender su di me il disonore, dar anche mio figlio, ma... non sarebbe meglio? Del resto, fa quello che vuoi....\n",
      "PREDICTED:  S , s  grid con voce stridula ,  io lo , e io non lo , ma non ci , ma non ci .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Well, if only because that woman is there, with whom you cannot associate...'\n",
      "TARGET:  Ma via, non fosse altro che per il fatto che l c quella donna di cui tu non puoi fare la conoscenza.\n",
      "PREDICTED:  E se non  perch , perch non  venuto da chi non pu essere ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 02: 100%|| 3638/3638 [26:34<00:00,  2.28it/s, loss=3.543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"Georgiana, a more vain and absurd animal than you was certainly never allowed to cumber the earth.\n",
      "TARGET:  Georgiana, un animale pi vano e pi stupido di voi, non ha certo avuto mai il diritto di ingombrare la terra.\n",
      "PREDICTED:  Georgiana ,  rispose ,  che non vi siete pi di .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And if the Venetians and Florentines formerly extended their dominions by these arms, and yet their captains did not make themselves princes, but have defended them, I reply that the Florentines in this case have been favoured by chance, for of the able captains, of whom they might have stood in fear, some have not conquered, some have been opposed, and others have turned their ambitions elsewhere.\n",
      "TARGET: E, se Viniziani e Fiorentini hanno per lo adrieto cresciuto lo imperio loro con queste arme, e li loro capitani non se ne sono per fatti principi ma li hanno difesi, respondo che Fiorentini in questo caso sono suti favoriti dalla sorte; perch de' capitani virtuosi, de' quali potevano temere, alcuni non hanno vinto, alcuni hanno avuto opposizione, altri hanno volto la ambizione loro altrove.\n",
      "PREDICTED: E se il loro e con quelle arme , e ' , non li ' loro principi , ma non ho ancora avuto alcuno ; ma , che li con li ' tempi , li ' tempi , li ' tempi , li ' tempi hanno avuto paura , li faccino con li faccino .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 03: 100%|| 3638/3638 [26:34<00:00,  2.28it/s, loss=3.277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: But what struck her most was the change that had taken place in Anna, whom she knew and loved.\n",
      "TARGET: Ma pi di tutto la stupiva il cambiamento avvenuto nellAnna che conosceva e amava.\n",
      "PREDICTED: Ma che le piaceva pi il cambiamento che era Anna , che Anna era innamorata di lei , e lo sapeva .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And to show that all was now well and satisfactory, she slightly opened her mouth, smacked her sticky lips, and drawing them more closely over her old teeth lay still in blissful peace.\n",
      "TARGET: E a mostrar che ora stava bene, che era contenta, apr leggermente la bocca, schiocc un po con le labbra e, accostate ai vecchi denti le labbra bavose, sacquiet in una calma beata.\n",
      "PREDICTED: E per mostrare che era bene , e si apr , apr la bocca , le labbra , le labbra , le labbra , i suoi , i suoi baci .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 04: 100%|| 3638/3638 [26:35<00:00,  2.28it/s, loss=2.821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: This is not only ungenerous, but not even gentlemanly  to hit one who is down.'\n",
      "TARGET: Io non dico che questo sia poco generoso, ma  disonesto percuotere chi  a terra.\n",
      "PREDICTED: Non solo non solo , ma a cui si far , la cosa sola .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: During the Parliamentary struggle, Reading was besieged by the Earl of Essex, and, a quarter of a century later, the Prince of Orange routed King James's troops there.\n",
      "TARGET: Durante la lotta parlamentare, Reading fu assediata dal conte di Essex, e, un quarto di secolo pi tardi, il principe dOrange vi sbaragli le truppe del re Giacomo.\n",
      "PREDICTED: In genere si , a Reading , il conte , e a un quarto d  inverno , il principe chiam le dimissioni del quale si pu avere un certo grado di ammirare le mie forze .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 05: 100%|| 3638/3638 [26:36<00:00,  2.28it/s, loss=2.705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: But granted a prince who has established himself as above, who can command, and is a man of courage, undismayed in adversity, who does not fail in other qualifications, and who, by his resolution and energy, keeps the whole people encouragedsuch a one will never find himself deceived in them, and it will be shown that he has laid his foundations well.\n",
      "TARGET: Ma, sendo uno principe che vi fondi su, che possa comandare e sia uomo di core, n si sbigottisca nelle avversit, e non manchi delle altre preparazioni, e tenga con lanimo et ordini sua animato luniversale, mai si troverr ingannato da lui, e li parr avere fatto li sua fondamenti buoni.\n",
      "PREDICTED: Ma uomo principe principe che ha principe , come uomo che pu avere , e che in uno di sopra , el principe che non si vede in altri , che in tutta la sua autorit ha , e in questo si tutto il populo all  altro , non si sar mai buono in una modo tale , che lui ha tenuto lui .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: If it is good for you, why not for everybody?'\n",
      "TARGET: Se la scuola  buona per te, lo  anche per gli altri.\n",
      "PREDICTED: Se vuoi bene , per la ragione , per tutti ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 06: 100%|| 3638/3638 [26:39<00:00,  2.27it/s, loss=2.247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I took no note of the lapse of time--of the change from morning to noon, from noon to evening.\n",
      "TARGET: Non mi accorgevo del tempo, non sapevo se era giorno o notte.\n",
      "PREDICTED: Non ho minor relazione di una giornata , di quel tempo , di trovarvi la sera fino all ' ora .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I feared nothing but interruption, and that came too soon.\n",
      "TARGET: Temevo soltanto una interruzione, che non tard.\n",
      "PREDICTED: Non , ma d  essere anche d  essere pure .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 07: 100%|| 3638/3638 [26:39<00:00,  2.27it/s, loss=1.953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: The jury all wrote down on their slates, 'She doesn't believe there's an atom of meaning in it,' but none of them attempted to explain the paper.\n",
      "TARGET: I giurati scrissero tutti sulla lavagna: Ella non crede che vi sia in esso neppure un atomo di buon senso.Ma nessuno cerc di spiegare il significato del foglio.\n",
      "PREDICTED: I giurati si a scrivere delle loro lavagne , non li ha data , ma la possibilit di non trovare nessuno .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Nowadays oats are forty-five kopeks at the inns.\n",
      "TARGET: Al giorno doggi lavena, dai portieri, sta a quarantacinque copeche.\n",
      "PREDICTED: ora a quaranta anni , gli apparvero di quaranta .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 08: 100%|| 3638/3638 [26:35<00:00,  2.28it/s, loss=1.941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: If I hadn't woke you, you'd have lain there for the whole fortnight.\"\n",
      "TARGET: Se io non ti avessi svegliato, saresti rimasto a letto per tutta la quindicina.\n",
      "PREDICTED: Se non fossi stata una campana che vi tocchi , che tutti vi sarebbe rimasta tutta la divertirci .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Just consider him!\n",
      "TARGET:  Ma pensa, chi sa come sta?\n",
      "PREDICTED:  Prima di lui , lo sapete .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 09: 100%|| 3638/3638 [26:37<00:00,  2.28it/s, loss=1.574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Round the camp-fire in the market-place gather still more of the Barons' troops, and eat and drink deep, and bellow forth roystering drinking songs, and gamble and quarrel as the evening grows and deepens into night.\n",
      "TARGET: Intorno al fuoco dellaccampamento, in piazza, si raccolgono le altre truppe dei baroni, e mangiano e bevono a pi non posso, e muggono canzoni dorgia, e giuocano e litigano come la sera savanza e sapprofondisce nella notte.\n",
      "PREDICTED: tutt  altro che nel luogo dei contadini lo spazio dei baroni , e i , e il bevuto , e , nella notte , e la notte innanzi alle pi cupe condizioni .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"No, you are wrong. And now, never mind what I have been: don't trouble your head further about me; but tell me the name of the house where we are.\"\n",
      "TARGET:  No, v'ingannate, ma poco importa ci che facevo, non ci pensate; ditemi piuttosto come si chiama questa casa.\n",
      "PREDICTED:  No , non lo dite ; ma in quel momento non sono stata pi nulla , e in risposta :  Non voglio darmi la casa , dove si sente qui ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 10: 100%|| 3638/3638 [26:35<00:00,  2.28it/s, loss=1.841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: This gave me not only egress and regress, as it was a back way to my tent and to my storehouse, but gave me room to store my goods.\n",
      "TARGET: Ci mi diede non solamente una porta di soccorso, per cos esprimermi, che mi agevolava luscita e lentrata cos nella palizzata come nella grotta, ma un maggiore spazio per allogarvi le cose mie.\n",
      "PREDICTED: Non solo mi dava fastidio e , quanto era a modo di fare il tenda e la mia tenda per essa andai in mano .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: The captain now had no difficulty before him, but to furnish his two boats, stop the breach of one, and man them.\n",
      "TARGET: Il capitano non era pi rattenuto da altri indugi fuor quello di allestire le due scialuppe, ristuccare cio il forame fatto nelluna, entrambe guarnirle e fornirle duomini.\n",
      "PREDICTED: Non gli altri , non senza , non senza le due barche , di la parte di un uomo di , la punta di nuovi .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 11: 100%|| 3638/3638 [26:35<00:00,  2.28it/s, loss=1.641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Kitty was unmarried and ill, and ill for love of the man who had slighted her.\n",
      "TARGET: Kitty tuttora nubile e malata, malata damore per luomo che laveva disdegnata!\n",
      "PREDICTED: Kitty non si vergognava e non voleva forse bene il nome di lei .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: _Friday_.Yes, I have been here (points to the NW. side of the island, which, it seems, was their side).\n",
      "TARGET:  S, essermi trovato; in questa mi accenn il nord-west (maestro) dellisola che sembra fosse la parte consueta del loro sbarco.\n",
      "PREDICTED:  S , signore , io volessi , principalmente la parte d  un lato .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 12: 100%|| 3638/3638 [26:34<00:00,  2.28it/s, loss=1.816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Friday had not been long gone when he came running back, and flew over my outer wall or fence, like one that felt not the ground or the steps he set his foot on; and before I had time to speak to him he cries out to me, O master! O master!\n",
      "TARGET: Venerd non istette lungo tempo, che torn addietro tutto ansante, e, scalato il piccolo muro della mia fortezza, corse a me che i suoi piedi non toccavano terra.  Ah padrone! padrone!\n",
      "PREDICTED: Venerd non era ancora . Uno dei due passi in me , e la mia parte si fermarono sul muro , mi sentiva che o l  indomani gli alberi s  con la sua paura di fare :   , egli mio padrone !\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'That's none of your business, Two!' said Seven.\n",
      "TARGET:  Questo non ti riguarda, Due!  rispose Sette.\n",
      "PREDICTED:  Questo non  affar da loro ,  rispose Diana .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 13: 100%|| 3638/3638 [26:38<00:00,  2.28it/s, loss=1.648]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: He wants, first of all, to legitimatize his daughter and to be your husband and have a right to you.'\n",
      "TARGET: Egli vuole, in primo luogo, legittimare sua figlia ed essere tuo marito, aver diritto su di te.\n",
      "PREDICTED: Prima di tutto , alla figlia , alla vostra figliuola e familiare  tuo marito .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: He still slowly moved his finger over his upper lip, and still his eye dwelt dreamily on the glowing grate; thinking it urgent to say something, I asked him presently if he felt any cold draught from the door, which was behind him.\n",
      "TARGET: Egli continuava ad agitare lentamente un dito sul labbro superiore e l'occhio era fisso sul fuoco. Per rompere il silenzio gli domandai se gli dava noia la porta, che aveva dietro.\n",
      "PREDICTED: Si sent il dito nelle sue labbra , senza dubbio quello che si diceva , entrando , e , come stava ad pensare a Si sarebbe detto qualcosa , di penosa , che gli sembrava dietro di vergogna , le porte , si sent dietro qualcosa che s  era coricato di dietro .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 14: 100%|| 3638/3638 [26:38<00:00,  2.28it/s, loss=1.676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Vronsky sat at the head of the table; on his right was the young Governor, a General of the Emperor's suite.\n",
      "TARGET: Vronskij sedeva a capotavola, alla sua destra sedeva il governatore, generale di corte.\n",
      "PREDICTED: Vronskij sedeva la testa del salotto , sulla tavola , nel giovane carrozza che portavano al governatore , alquanto imperatore di provincia .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Only he left very early.'\n",
      "TARGET: Ma  andato via un po presto.\n",
      "PREDICTED: Solo di questo ci rimaneva molto .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 15: 100%|| 3638/3638 [26:35<00:00,  2.28it/s, loss=1.678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"I should think you ought to be at home yourself,\" said he, \"if you have a home in this neighbourhood: where do you come from?\"\n",
      "TARGET:  Mi pare che anche voi a quest'ora, dovreste essere a casa, se abitate vicino. Di dove venite?\n",
      "PREDICTED:  S , ci dovrebbe essere reso colpevole di casa ,  disse ,  che in casa dove la poteva entrare ?\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: They speak of divorce.\n",
      "TARGET: Mi dicono: il divorzio.\n",
      "PREDICTED: Esse parlano col divorzio .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 16: 100%|| 3638/3638 [26:36<00:00,  2.28it/s, loss=1.819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: The truth was, we were too clever for them.\n",
      "TARGET: La verit era che per loro eravamo noi troppo alti.\n",
      "PREDICTED: Era vero , signora .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Just in the same way Kitty, besides all her cares about linen, bedsores, and cooling drinks, had managed on the very first day to persuade the invalid of the necessity of receiving Communion and Extreme Unction.\n",
      "TARGET: Katja, proprio alla stessa maniera, oltre tutte le preoccupazioni per la biancheria, per le piaghe, per le bevande, aveva fin dal primo giorno convinto il malato della necessit di comunicarsi e di ricevere lestrema unzione.\n",
      "PREDICTED: In realt , anche in piacevole Kitty , si presentavano veramente per le spalle , il primo segno , che se non avesse finito l  abbiamo parlato della necessit di , il malato e l  hanno accolta l  intera .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 17: 100%|| 3638/3638 [26:37<00:00,  2.28it/s, loss=1.599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'There is a way out of every position.\n",
      "TARGET:  Da qualsiasi situazione c una via duscita.\n",
      "PREDICTED:  In qualsiasi situazione  de  tentativi di apparire .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: The Marshal of the Province, though he felt in the air that there was a plot prepared against him, and though he had not been unanimously asked to stand, had still decided to do so.\n",
      "TARGET: Il maresciallo del governatorato, malgrado sentisse nellaria linganno preparatogli, e malgrado non tutti lavessero pregato, decise tuttavia di entrare in ballottaggio.\n",
      "PREDICTED: Il maresciallo del governatorato era gi pieno di cura che , lo sentiva in una aria abbastanza sorte , e pure non aveva neppure a decidersi poi a se stessa .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 18: 100%|| 3638/3638 [26:37<00:00,  2.28it/s, loss=1.591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: When we got back, it was after moonrise: a pony, which we knew to be the surgeon's, was standing at the garden door.\n",
      "TARGET: Quando giungemmo a casa, la luna era alta. Un cavallo, che riconoscemmo per quello del medico, era legato al cancello del giardino.\n",
      "PREDICTED: Quando tornammo di l , infatti era un poco seduta , di un singhiozzo che lo spazio del medico .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Ah, so you are here!' she said on seeing him. 'Well, how is your poor sister?\n",
      "TARGET:  Ah, anche voi siete qui  ella disse nel vederlo.  Be, come va la vostra povera sorella?\n",
      "PREDICTED:  Ah , s ;  qui da voi !  disse ella , come , nel vano della sorella .  come , Dio ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 19: 100%|| 3638/3638 [26:34<00:00,  2.28it/s, loss=1.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Why, the day is already commenced which is to bind us indissolubly; and when we are once united, there shall be no recurrence of these mental terrors: I guarantee that.\"\n",
      "TARGET: Il giorno che deve vederci uniti  gi incominciato e quando sarete mia, vi assicuro che non avrete pi queste paure immaginarie.\n",
      "PREDICTED: Ma il giorno  gi stata fortuna e da parte di quello che sono , e quando sono una volta d ' una volta : un vago che riguardava la sua vita m ' .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Gazing into her face and laughing and shouting unnaturally they again passed by.\n",
      "TARGET: Di nuovo le passarono accanto, guardandola in viso e gridando fra le risa qualcosa con voce contraffatta.\n",
      "PREDICTED: il viso e ridendo e molta disinvoltura .\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c25e9",
   "metadata": {
    "papermill": {
     "duration": 6.453373,
     "end_time": "2025-09-30T17:53:15.773096",
     "exception": false,
     "start_time": "2025-09-30T17:53:09.319723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32031.061889,
   "end_time": "2025-09-30T17:53:24.757428",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-30T08:59:33.695539",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "043a7f4a7f4146d29269ef0bc4868a87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "05d7eee5c9f94f26a8708a07500e63e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "11a0d6b1eb774191b69d03978931dd8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1d150f9362454b7ebbfca9393f0886ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3176e33a6beb4acca4f1ca75dbdeafdc",
       "max": 32332.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_282fdc6194c54efba87167cffc8b8e60",
       "tabbable": null,
       "tooltip": null,
       "value": 32332.0
      }
     },
     "2226ef895dc8462a92eb6978b5b9c088": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9c800b46a5dd423c8ad6e6fec96f0dcd",
        "IPY_MODEL_7946397cda714844b6c295502412ad45",
        "IPY_MODEL_774317007a69438d93fdf6eee5d53afe"
       ],
       "layout": "IPY_MODEL_2d1cab7c2f1b48a58768ad306b1dbb26",
       "tabbable": null,
       "tooltip": null
      }
     },
     "26f3adab8af44b0b9d3c45d9774ca4f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "282fdc6194c54efba87167cffc8b8e60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2d1cab7c2f1b48a58768ad306b1dbb26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3176e33a6beb4acca4f1ca75dbdeafdc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3183b1b26c6a47639ead96cce4a8bf73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3345ccfa2d6a405c9226a4c509ba3177": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3518cebb0e4847fcafb7b63c2b5c944f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_70b5c38fd5494f528aa38dcd73ec9f1a",
       "placeholder": "",
       "style": "IPY_MODEL_7a630cc063ea4fd78222d6febcabe150",
       "tabbable": null,
       "tooltip": null,
       "value": "5.73M/5.73M[00:00&lt;00:00,7.52MB/s]"
      }
     },
     "3f1bafa2f1b04af9aa6bdda902f411b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_77db33779d234ca08e89c57d6eee7c40",
       "placeholder": "",
       "style": "IPY_MODEL_ba4fc1afc92c40969f8f2392ed076122",
       "tabbable": null,
       "tooltip": null,
       "value": "en-it/train-00000-of-00001.parquet:100%"
      }
     },
     "4eccad1a3c454a7d8b35091a2cd29512": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "524b88ada29c4dc7aeeeea6fb30d4a00": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f6be351af5b4ea5b0b80d5c8aeec1bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "606b1906ac4f4a9fa9e2917d7016dd5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6686169085cf40ea9c9441839c270e1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4eccad1a3c454a7d8b35091a2cd29512",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_11a0d6b1eb774191b69d03978931dd8d",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "678d6f82047340d3b59210d7153898d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6c6449f6ad294a628405214c7964e4cf",
        "IPY_MODEL_6686169085cf40ea9c9441839c270e1d",
        "IPY_MODEL_737417694ed64c0a8260e8e478983ee5"
       ],
       "layout": "IPY_MODEL_ddb0c89520ff4fb6ade4abb8aeff6742",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6c6449f6ad294a628405214c7964e4cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_05d7eee5c9f94f26a8708a07500e63e7",
       "placeholder": "",
       "style": "IPY_MODEL_606b1906ac4f4a9fa9e2917d7016dd5e",
       "tabbable": null,
       "tooltip": null,
       "value": "README.md:"
      }
     },
     "70b5c38fd5494f528aa38dcd73ec9f1a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "737417694ed64c0a8260e8e478983ee5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e702c1dcfe0d420594e7b60d1fec150e",
       "placeholder": "",
       "style": "IPY_MODEL_3345ccfa2d6a405c9226a4c509ba3177",
       "tabbable": null,
       "tooltip": null,
       "value": "28.1k/?[00:00&lt;00:00,2.84MB/s]"
      }
     },
     "774317007a69438d93fdf6eee5d53afe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_043a7f4a7f4146d29269ef0bc4868a87",
       "placeholder": "",
       "style": "IPY_MODEL_9ae1e897aa2a4f4a976d3e4a54cf1977",
       "tabbable": null,
       "tooltip": null,
       "value": "1/1[00:00&lt;00:00,172.06it/s]"
      }
     },
     "77af2b96b86c43aa9b0c3a9c372f679f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3f1bafa2f1b04af9aa6bdda902f411b5",
        "IPY_MODEL_82f3a0ced59f41cfab43e4569fae345b",
        "IPY_MODEL_3518cebb0e4847fcafb7b63c2b5c944f"
       ],
       "layout": "IPY_MODEL_b96232dc1d1f41179976c52d687a159d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "77db33779d234ca08e89c57d6eee7c40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7946397cda714844b6c295502412ad45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d1d250d501c547dfa6750725b4679711",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8f23da7a164d4aa58051c7450851747c",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "7a630cc063ea4fd78222d6febcabe150": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "82f3a0ced59f41cfab43e4569fae345b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b662a2ca6474477aae3cb0c1d1b09c5a",
       "max": 5726189.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f3ee00a3e208472f9f54ea12c5c023c8",
       "tabbable": null,
       "tooltip": null,
       "value": 5726189.0
      }
     },
     "8834220416b942c6bc25fa3724b8ab83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f23da7a164d4aa58051c7450851747c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "998fa4fb2d3e4d25a09ba1a791f06318": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ae1e897aa2a4f4a976d3e4a54cf1977": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9c800b46a5dd423c8ad6e6fec96f0dcd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_998fa4fb2d3e4d25a09ba1a791f06318",
       "placeholder": "",
       "style": "IPY_MODEL_3183b1b26c6a47639ead96cce4a8bf73",
       "tabbable": null,
       "tooltip": null,
       "value": "Computingchecksums:100%"
      }
     },
     "b662a2ca6474477aae3cb0c1d1b09c5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b96232dc1d1f41179976c52d687a159d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba4fc1afc92c40969f8f2392ed076122": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c3fcb4caf6354d00943eaa4738754831": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5f6be351af5b4ea5b0b80d5c8aeec1bf",
       "placeholder": "",
       "style": "IPY_MODEL_dc6e20d05ec14ac7b90e7174640dd3f3",
       "tabbable": null,
       "tooltip": null,
       "value": "Generatingtrainsplit:100%"
      }
     },
     "cf2ec21996ab43b7aaf602929cd99e1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c3fcb4caf6354d00943eaa4738754831",
        "IPY_MODEL_1d150f9362454b7ebbfca9393f0886ec",
        "IPY_MODEL_e63676e1027f457c94de4531355deb5b"
       ],
       "layout": "IPY_MODEL_524b88ada29c4dc7aeeeea6fb30d4a00",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d1d250d501c547dfa6750725b4679711": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc6e20d05ec14ac7b90e7174640dd3f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ddb0c89520ff4fb6ade4abb8aeff6742": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e63676e1027f457c94de4531355deb5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8834220416b942c6bc25fa3724b8ab83",
       "placeholder": "",
       "style": "IPY_MODEL_26f3adab8af44b0b9d3c45d9774ca4f2",
       "tabbable": null,
       "tooltip": null,
       "value": "32332/32332[00:00&lt;00:00,249365.15examples/s]"
      }
     },
     "e702c1dcfe0d420594e7b60d1fec150e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f3ee00a3e208472f9f54ea12c5c023c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
